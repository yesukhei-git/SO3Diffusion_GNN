{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180eaf69-31e6-4aec-a341-0e4a3497f572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 15:33:40.358868: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import tensorflow_probability as tfp; tfp = tfp.substrates.jax\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "from jaxlie import SO3\n",
    "from so3dm.distributions.isotropic_gaussian import IsotropicGaussianSO3\n",
    "from so3dm.plotting import visualize_so3_probabilities, visualize_so3_density\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "from flax.metrics import tensorboard\n",
    "import haiku as hk\n",
    "import optax\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8071a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import radius_neighbors_graph\n",
    "import jraph\n",
    "from jraph import GraphConvolution\n",
    "from jraph._src import utils as jraph_utils\n",
    "from jraph._src import graph as gn_graph\n",
    "\n",
    "import networkx as nx\n",
    "import jax.tree_util as tree\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb694466-e71a-4d8f-aa2a-b10ca6462380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_force_compilation_parallelism=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0594215-29ad-4b41-a9a0-ad0c4fabf896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.linalg.inv(jnp.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a121dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = hk.PRNGSequence(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6263e366-af61-41c1-988c-63edddf0aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from halotools_ia.correlation_functions import  ed_3d, ee_3d,gi_plus_3d, gi_plus_projected, ii_minus_3d, ii_minus_projected, ii_plus_3d, ii_plus_projected, ed_projected, ed_3d_one_two_halo_decomp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ee030ed-0c33-4497-958c-23ecb05d73d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tng = pickle.load(  open('/jet/home/yjagvara/SO3Diffusion_Tidal/TNG100-1_99_non-reduced_galaxy_shapes_multi_scale_1024_MLP_only_cent.pkl', \"rb\" ) )\n",
    "tng = tng[tng['dm_mass']>0]\n",
    "tng = tng[log10(tng['dm_mass']*10**10)>9]\n",
    "tng = tng[log10(tng['mass']*10**10)>9]\n",
    "\n",
    "tng['mass'] = log10(tng['mass']*10**10)\n",
    "tng['dm_mass'] = log10(tng['dm_mass']*10**10)\n",
    "\n",
    "#tng = tng[tng['central_bool']==1.0]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9538258",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=17457</i>\n",
       "<table id=\"table22508822514416\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>gal_id</th><th>a</th><th>b</th><th>c</th><th>av_x</th><th>av_y</th><th>av_z</th><th>bv_x</th><th>bv_y</th><th>bv_z</th><th>cv_x</th><th>cv_y</th><th>cv_z</th><th>tid_av_x_0.1_1024</th><th>tid_av_y_0.1_1024</th><th>tid_av_z_0.1_1024</th><th>tid_bv_x_0.1_1024</th><th>tid_bv_y_0.1_1024</th><th>tid_bv_z_0.1_1024</th><th>tid_cv_x_0.1_1024</th><th>tid_cv_y_0.1_1024</th><th>tid_cv_z_0.1_1024</th><th>tid_a_0.1_1024</th><th>tid_b_0.1_1024</th><th>tid_c_0.1_1024</th><th>tid_av_x_0.5_1024</th><th>tid_av_y_0.5_1024</th><th>tid_av_z_0.5_1024</th><th>tid_bv_x_0.5_1024</th><th>tid_bv_y_0.5_1024</th><th>tid_bv_z_0.5_1024</th><th>tid_cv_x_0.5_1024</th><th>tid_cv_y_0.5_1024</th><th>tid_cv_z_0.5_1024</th><th>tid_a_0.5_1024</th><th>tid_b_0.5_1024</th><th>tid_c_0.5_1024</th><th>tid_av_x_1.0_1024</th><th>tid_av_y_1.0_1024</th><th>tid_av_z_1.0_1024</th><th>tid_bv_x_1.0_1024</th><th>tid_bv_y_1.0_1024</th><th>tid_bv_z_1.0_1024</th><th>tid_cv_x_1.0_1024</th><th>tid_cv_y_1.0_1024</th><th>tid_cv_z_1.0_1024</th><th>tid_a_1.0_1024</th><th>tid_b_1.0_1024</th><th>tid_c_1.0_1024</th><th>tid_av_x_2.0_1024</th><th>tid_av_y_2.0_1024</th><th>tid_av_z_2.0_1024</th><th>tid_bv_x_2.0_1024</th><th>tid_bv_y_2.0_1024</th><th>tid_bv_z_2.0_1024</th><th>tid_cv_x_2.0_1024</th><th>tid_cv_y_2.0_1024</th><th>tid_cv_z_2.0_1024</th><th>tid_a_2.0_1024</th><th>tid_b_2.0_1024</th><th>tid_c_2.0_1024</th><th>mass</th><th>GroupID</th><th>tot_mass</th><th>dm_mass</th><th>central_bool</th><th>group_mass</th><th>group_x</th><th>group_y</th><th>group_z</th><th>gal_pos_x</th><th>gal_pos_y</th><th>gal_pos_z</th><th>dm_av_x</th><th>dm_av_y</th><th>dm_av_z</th><th>dm_bv_x</th><th>dm_bv_y</th><th>dm_bv_z</th><th>dm_cv_x</th><th>dm_cv_y</th><th>dm_cv_z</th><th>dm_a</th><th>dm_b</th><th>dm_c</th><th>mlp_av_x</th><th>mlp_av_y</th><th>mlp_av_z</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>0.0</td><td>0.24562844247483243</td><td>0.11233008826530698</td><td>0.09435347356932028</td><td>0.15057356009311798</td><td>-0.36432524666271543</td><td>0.9190183445639349</td><td>-0.6040801058750838</td><td>0.7019725376704176</td><td>0.37725559246020707</td><td>0.7825693762771655</td><td>0.611965416507098</td><td>0.11438312949234405</td><td>0.8275753855705261</td><td>0.5501617810833461</td><td>-0.11153932645318682</td><td>-0.4364806852752775</td><td>0.7555949692944677</td><td>0.4884269175204382</td><td>0.3529923768186143</td><td>-0.355525325415916</td><td>0.8654467776217399</td><td>1054.244087225318</td><td>991.9027130436707</td><td>668.0261137005616</td><td>-0.9183833599090576</td><td>0.33972494317589014</td><td>0.20287679547321114</td><td>0.33534699111399274</td><td>0.9403888675675559</td><td>-0.05666721544068841</td><td>-0.2100343464963115</td><td>0.015991896046057438</td><td>-0.9775632115381181</td><td>59.10935058615099</td><td>55.377614125575626</td><td>37.975054282341716</td><td>0.9371282458305359</td><td>0.1784244452709745</td><td>-0.29992566920893826</td><td>-0.2053100234179685</td><td>0.9768323454844315</td><td>-0.06038512316371721</td><td>0.2822029128212493</td><td>0.11816634946180396</td><td>0.9520494891811419</td><td>13.122050507836377</td><td>11.700347539646893</td><td>9.282237732126015</td><td>-0.8248880505561829</td><td>0.33217499988277654</td><td>0.4574051124728157</td><td>0.5063412900419841</td><td>0.7939398479662237</td><td>0.3365679958195495</td><td>-0.2513526714837356</td><td>0.5092340201363678</td><td>-0.8231054290148635</td><td>2.5250096232145673</td><td>2.341083724345102</td><td>1.7858375325765965</td><td>12.3997019439012</td><td>0.0</td><td>27477.935546875</td><td>14.36783318021225</td><td>1.0</td><td>38878.03515625</td><td>849.0914306640625</td><td>26326.99609375</td><td>18306.93359375</td><td>0.8490914106369019</td><td>26.326995849609375</td><td>18.306934356689453</td><td>0.20913785733198287</td><td>-0.2376266091458571</td><td>0.9485752217175131</td><td>-0.0291868731156354</td><td>0.9680772186306577</td><td>0.24894703293283385</td><td>0.9774505015950008</td><td>0.07975019369363229</td><td>-0.19552601754628252</td><td>0.7422561814889702</td><td>0.380580342545896</td><td>0.2953753041796042</td><td>-0.8295962810516357</td><td>0.51895672082901</td><td>0.5298088788986206</td></tr>\n",
       "<tr><td>1.0</td><td>0.08088470650058953</td><td>0.04497213832247513</td><td>0.03777383880658522</td><td>-0.9840750455762398</td><td>-0.006859759853817557</td><td>0.17762108086843106</td><td>0.07866214907516236</td><td>0.8792771126813137</td><td>0.46977018361927686</td><td>-0.15940066178344028</td><td>0.4762611707976621</td><td>-0.8647350612837673</td><td>-0.25285616517066956</td><td>-0.542943046543665</td><td>-0.8007974784346137</td><td>-0.0015899779481896464</td><td>-0.8274600252025045</td><td>0.5615223759228073</td><td>0.9675025711735737</td><td>-0.14325765215776112</td><td>-0.20836511193280413</td><td>340.0297044488053</td><td>304.0921077455601</td><td>251.82406385313607</td><td>-0.43189844489097595</td><td>-0.6954925306839556</td><td>-0.5742419895334245</td><td>-0.7976906521230697</td><td>0.5916774294264403</td><td>-0.11665094522888154</td><td>-0.4208958853397719</td><td>-0.40768610384724513</td><td>0.810332459200483</td><td>19.602475741375493</td><td>17.40369819653049</td><td>5.434223834232313</td><td>0.46768128871917725</td><td>0.777220230781344</td><td>0.42095478906302564</td><td>0.802480656776426</td><td>-0.5730060672469052</td><td>0.1663996466279646</td><td>0.3705388199238754</td><td>0.25998607609337393</td><td>-0.8916884114795887</td><td>6.901495930274793</td><td>5.321455175040075</td><td>-0.37971657154338395</td><td>-0.3023521304130554</td><td>-0.8591983176887451</td><td>0.4127486479698836</td><td>-0.8679340461933621</td><td>0.4271650525814584</td><td>0.2534176578526006</td><td>-0.3940478232125578</td><td>-0.2816172379914081</td><td>-0.874881731600069</td><td>2.041410478830176</td><td>1.404129183064541</td><td>1.2895440686703488</td><td>11.578095147604138</td><td>0.0</td><td>3666.622802734375</td><td>13.50298481399793</td><td>0.0</td><td>38878.03515625</td><td>849.0914306640625</td><td>26326.99609375</td><td>18306.93359375</td><td>0.10647333413362503</td><td>24.63332176208496</td><td>16.90055274963379</td><td>-0.894172344445321</td><td>-0.431108424887396</td><td>-0.12083602285852724</td><td>-0.4150634625674986</td><td>0.6969958927253865</td><td>0.5847384437211395</td><td>0.16786345781806322</td><td>-0.5730115631599854</td><td>0.8021718070428016</td><td>0.2554090437812483</td><td>0.18938552774748685</td><td>0.17268245195140966</td><td>-0.6350778937339783</td><td>-0.5722015500068665</td><td>0.8127713799476624</td></tr>\n",
       "<tr><td>2.0</td><td>0.029657668413294556</td><td>0.027907432725562016</td><td>0.025816469838701374</td><td>-0.26077723253654983</td><td>0.4254462113472258</td><td>-0.8665972283828683</td><td>0.9558149884532077</td><td>-0.012390405194009673</td><td>-0.2937076534707986</td><td>0.13569429921250462</td><td>0.9048988888872719</td><td>0.40341673000980943</td><td>-0.880781888961792</td><td>0.44753759161619305</td><td>0.15470422818181326</td><td>0.47337510537536415</td><td>0.8403335008773494</td><td>0.26411288668688704</td><td>-0.011802700445901449</td><td>0.3058589730473757</td><td>-0.9520036685163501</td><td>382.3485118800341</td><td>379.8080753150767</td><td>229.73399493712893</td><td>0.9019741415977478</td><td>0.39395049048399733</td><td>0.17676446381355537</td><td>-0.4301801316453484</td><td>0.8551803839966307</td><td>0.2891566446840985</td><td>0.0372521000410273</td><td>0.3368523740079518</td><td>-0.9408202586933065</td><td>45.55879223874659</td><td>41.7458650873896</td><td>13.936163208857044</td><td>-0.8888373374938965</td><td>-0.36896232896961634</td><td>-0.27172599523478264</td><td>0.43208303553659616</td><td>-0.8722901430712391</td><td>-0.2289413826773946</td><td>-0.15255316150934772</td><td>-0.3208998381147507</td><td>0.934746397057207</td><td>12.192577897497326</td><td>10.585406962788612</td><td>7.440784034136231</td><td>0.8154981732368469</td><td>0.34012826538765034</td><td>-0.46826861664919506</td><td>-0.5509893239287479</td><td>0.7038767719183728</td><td>-0.4482948302962152</td><td>0.17712565926681462</td><td>0.623594622361482</td><td>0.7614172626038479</td><td>2.512468517480205</td><td>2.328128810399225</td><td>1.7195177630093514</td><td>11.628209423407583</td><td>0.0</td><td>773.4555053710938</td><td>12.856235701293752</td><td>0.0</td><td>38878.03515625</td><td>849.0914306640625</td><td>26326.99609375</td><td>18306.93359375</td><td>0.8531123399734497</td><td>26.72574806213379</td><td>17.510679244995117</td><td>-0.44998482120148936</td><td>0.5216721585493953</td><td>-0.7248253718535784</td><td>0.1483677084347021</td><td>-0.7566904268686213</td><td>-0.6367154945336407</td><td>0.8806251664483017</td><td>0.39405298740118433</td><td>-0.2630999037211969</td><td>0.06412549909992203</td><td>0.06279831222742362</td><td>0.05986077141319621</td><td>-0.5391837954521179</td><td>-0.1834503561258316</td><td>0.2371581792831421</td></tr>\n",
       "<tr><td>3.0</td><td>0.018082525231503666</td><td>0.014158971881358921</td><td>0.01222966521600501</td><td>-0.18327640118347924</td><td>0.8024303076072575</td><td>-0.5679043600841203</td><td>0.9766838307247415</td><td>0.21432650432834124</td><td>-0.0123630232240266</td><td>-0.11179649176104173</td><td>0.5569288562964891</td><td>0.823001697115023</td><td>0.9721372723579407</td><td>0.13241262915181962</td><td>-0.19343225375726192</td><td>-0.2253100707952795</td><td>0.7555232597061101</td><td>-0.6151584966829927</td><td>0.06468781300011002</td><td>0.6416007322970851</td><td>0.7643062129572853</td><td>87.04871759916425</td><td>84.99975852487485</td><td>62.34963110912915</td><td>0.9601742029190063</td><td>0.09534201450948858</td><td>-0.26263176314282344</td><td>-0.11330683354213822</td><td>0.9920863922003901</td><td>-0.05409391725016924</td><td>0.2553959753302503</td><td>0.08169755614512844</td><td>0.9633786405692335</td><td>11.497520319686519</td><td>9.693721223067465</td><td>-3.8285132677798916</td><td>0.9453354477882385</td><td>0.18561979935204662</td><td>-0.2681158910993191</td><td>-0.207397898455762</td><td>0.9767054732929888</td><td>-0.05506841341142483</td><td>0.2516484704654678</td><td>0.1076647970695349</td><td>0.9618114881744583</td><td>6.208022837439617</td><td>5.142239415879281</td><td>-1.1519118757588624</td><td>0.9223912358283997</td><td>-0.07469076297867584</td><td>-0.3789666305250492</td><td>-0.341641069588688</td><td>-0.6155109176150187</td><td>-0.7102307300216</td><td>0.18021042338372953</td><td>-0.7845811622913088</td><td>0.593259305094725</td><td>2.089374436125829</td><td>1.9721288558379273</td><td>0.8042911796768404</td><td>11.065239627215188</td><td>0.0</td><td>339.1330871582031</td><td>12.492075007318201</td><td>0.0</td><td>38878.03515625</td><td>849.0914306640625</td><td>26326.99609375</td><td>18306.93359375</td><td>0.24545502662658691</td><td>26.517372131347656</td><td>15.888749122619629</td><td>0.07192887265149081</td><td>-0.602036263783214</td><td>0.7952223427249978</td><td>-0.06875971805707189</td><td>0.7923976582805746</td><td>0.6061171935559767</td><td>0.9950368528108882</td><td>0.09827659050562189</td><td>-0.015600426493936224</td><td>0.11019573989878745</td><td>0.08198181434064328</td><td>0.06754900596157654</td><td>-0.36452817916870117</td><td>-0.13807687163352966</td><td>0.38148462772369385</td></tr>\n",
       "<tr><td>4.0</td><td>0.01801164473834766</td><td>0.0168904028181911</td><td>0.013904951566977544</td><td>-0.1142639508855221</td><td>-0.979945945153804</td><td>-0.16324734026822255</td><td>-0.9934460645980511</td><td>0.1131971410280455</td><td>0.01585320149754536</td><td>-0.0029438516735695247</td><td>-0.16398887718285846</td><td>0.9864577952946744</td><td>0.7485275268554688</td><td>0.6600091975474459</td><td>0.06398781308005926</td><td>0.09984522831373491</td><td>-0.016784453435366945</td><td>-0.9948614036667893</td><td>-0.65554367623597</td><td>0.7510699975872106</td><td>-0.0784623939946852</td><td>95.48307820950194</td><td>84.8429631454686</td><td>74.73061250881207</td><td>-0.9893072247505188</td><td>-0.04843766873430373</td><td>0.137568123101957</td><td>0.08901581515380513</td><td>0.546642973525605</td><td>0.8326209486600661</td><td>0.1155308655672284</td><td>-0.8359636665206632</td><td>0.536486129698258</td><td>8.999897029588341</td><td>8.000785662629548</td><td>-3.7907557456801593</td><td>0.9832291603088379</td><td>-0.16407630175885704</td><td>-0.07962015991931036</td><td>-0.17963702753860372</td><td>-0.9466587978466704</td><td>-0.26752132400351225</td><td>-0.031479215389444815</td><td>0.2773374977543313</td><td>-0.9602567215790949</td><td>4.977716213338439</td><td>4.500357897673841</td><td>-1.9989919689628635</td><td>0.951259195804596</td><td>0.08308734405975979</td><td>-0.296988995835959</td><td>-0.30827944117927625</td><td>0.28227597115623293</td><td>-0.9084514638955671</td><td>-0.008352037880026354</td><td>-0.955728397278694</td><td>-0.2941317291594872</td><td>1.9237631510049509</td><td>1.8755596258083822</td><td>0.5238074617832662</td><td>10.955806928437847</td><td>0.0</td><td>325.36669921875</td><td>12.48691572674364</td><td>0.0</td><td>38878.03515625</td><td>849.0914306640625</td><td>26326.99609375</td><td>18306.93359375</td><td>0.7687843441963196</td><td>26.51828956604004</td><td>15.530523300170898</td><td>-0.7731495452799411</td><td>-0.025394237333196023</td><td>-0.6337151673612411</td><td>-0.38358190855097435</td><td>0.8144575707517007</td><td>0.4353432954320422</td><td>0.5050789047919271</td><td>0.5796671442780793</td><td>-0.6394382704989464</td><td>0.07512998409324027</td><td>0.07145462279941757</td><td>0.06208312340477497</td><td>-0.3841070532798767</td><td>0.06337937712669373</td><td>0.3301573693752289</td></tr>\n",
       "<tr><td>5.0</td><td>0.020714045769373805</td><td>0.015366443958998062</td><td>0.011101178523383154</td><td>0.4543514501412507</td><td>0.4368184773811964</td><td>0.7763725765203948</td><td>0.0989417327520005</td><td>0.8413858812125629</td><td>-0.5313006045697589</td><td>0.885310845564751</td><td>-0.3182128481292561</td><td>-0.3390653182071158</td><td>0.7768359780311584</td><td>0.15880068292379038</td><td>-0.6093506734152345</td><td>0.12258095443257752</td><td>-0.9873034088378564</td><td>-0.10102419763376748</td><td>0.6176567086165746</td><td>-0.0037844418460261536</td><td>0.7864387250770741</td><td>150.6719051410386</td><td>144.29760338145712</td><td>32.579406564684625</td><td>0.8302285671234131</td><td>0.06331149379261101</td><td>-0.5538160138923615</td><td>-0.010964905134195126</td><td>-0.9914818694743903</td><td>-0.12978240774067612</td><td>0.5573152549009173</td><td>-0.11382160277081475</td><td>0.8224623695935326</td><td>30.224059047691718</td><td>27.72795609148564</td><td>-5.601407306425997</td><td>0.8750212788581848</td><td>-0.013376262889044099</td><td>-0.4838995982078433</td><td>-0.07984628679003236</td><td>-0.9899146088434846</td><td>-0.11701981748445146</td><td>0.4774539936375365</td><td>-0.14103241751233508</td><td>0.8672644009586659</td><td>10.214945917008441</td><td>9.040170727109352</td><td>3.5761973690223474</td><td>-0.8614780902862549</td><td>0.16273267542655348</td><td>0.4810130892316824</td><td>0.32598990654872145</td><td>0.9035240204531997</td><td>0.2781634866269143</td><td>-0.3893405918884474</td><td>0.39643715871825347</td><td>-0.8314153490857331</td><td>2.3269508673959876</td><td>2.003771712772918</td><td>1.3924634090971475</td><td>11.114486029043341</td><td>0.0</td><td>298.01812744140625</td><td>12.451609934560004</td><td>0.0</td><td>38878.03515625</td><td>849.0914306640625</td><td>26326.99609375</td><td>18306.93359375</td><td>1.4265923500061035</td><td>26.341442108154297</td><td>19.04120445251465</td><td>0.3918429756654348</td><td>0.3654932744319969</td><td>0.8443185114437765</td><td>0.011168222931565</td><td>0.9157482681432102</td><td>-0.4015972860830387</td><td>0.9199643217093848</td><td>-0.1667926129589919</td><td>-0.35474761598085974</td><td>0.062249062652563976</td><td>0.04554774917427718</td><td>0.038746376495772214</td><td>-0.9575876593589783</td><td>0.2240697145462036</td><td>0.34571993350982666</td></tr>\n",
       "<tr><td>6.0</td><td>0.014119734858107792</td><td>0.011844378746852749</td><td>0.007982621187688364</td><td>-0.22290355721159702</td><td>0.2984316518790147</td><td>-0.9280369353313361</td><td>0.9394537387980854</td><td>-0.18840792189093264</td><td>-0.2862326459840651</td><td>-0.26027039178653266</td><td>-0.9356500436196766</td><td>-0.238365935137095</td><td>-0.9105023145675659</td><td>-0.0988293550637392</td><td>0.40151996746038326</td><td>0.41098426612009176</td><td>-0.10925613157905309</td><td>0.9050718373223812</td><td>0.04557914757245563</td><td>-0.9890883966006611</td><td>-0.1400952712139218</td><td>335.3875231376624</td><td>294.41755624107986</td><td>-42.357889451741656</td><td>0.8969227075576782</td><td>0.3906390273337473</td><td>0.20719759058429238</td><td>-0.4393241654870583</td><td>0.8404695553081605</td><td>0.3171832344547916</td><td>0.05023911662531079</td><td>0.37551574790392966</td><td>-0.9254533776678657</td><td>54.147985187340716</td><td>50.0636499904205</td><td>27.867718833217868</td><td>0.9127143025398254</td><td>-0.27453073013282103</td><td>0.30263098525806825</td><td>-0.3416022979844858</td><td>-0.919069329745677</td><td>0.1965182870181554</td><td>0.22418854796186125</td><td>-0.2827444877156255</td><td>-0.9326280339069702</td><td>12.92535772244448</td><td>11.247231530013353</td><td>9.113070946326427</td><td>-0.8143582344055176</td><td>0.3390340504565971</td><td>0.4710377874775135</td><td>0.5378165677834383</td><td>0.745882999514194</td><td>0.39295278400000105</td><td>-0.21811470381054063</td><td>0.5733362570662202</td><td>-0.789754083443028</td><td>2.539618561436438</td><td>2.3344824030547318</td><td>1.80247327951178</td><td>11.292302355114606</td><td>0.0</td><td>206.8306121826172</td><td>12.268136164748892</td><td>0.0</td><td>38878.03515625</td><td>849.0914306640625</td><td>26326.99609375</td><td>18306.93359375</td><td>0.9047555923461914</td><td>26.611112594604492</td><td>17.832447052001953</td><td>0.11291700663663792</td><td>-0.287765607234945</td><td>0.9510208751152229</td><td>0.978800736446974</td><td>-0.13239059141012582</td><td>-0.15627491685148434</td><td>0.17087676244323766</td><td>0.9485060287624851</td><td>0.26671603899678925</td><td>0.03274124656447151</td><td>0.02647658482026913</td><td>0.021759721217229116</td><td>-0.6157798171043396</td><td>0.1805431842803955</td><td>0.8364304900169373</td></tr>\n",
       "<tr><td>7.0</td><td>0.014264607282143125</td><td>0.012930660989750504</td><td>0.010384966439804553</td><td>-0.32911445366610587</td><td>0.2580640586333649</td><td>0.9083427866338432</td><td>0.9287466042611946</td><td>-0.08535148538246126</td><td>0.3607559687881924</td><td>-0.17062655555733508</td><td>-0.9623502821658456</td><td>0.2115857106563602</td><td>-0.5996925234794617</td><td>-0.7457408138106868</td><td>0.2902404295058079</td><td>0.09643116278398547</td><td>0.29270824713300736</td><td>0.9513269222010118</td><td>0.7943990805299755</td><td>-0.5984918718556634</td><td>0.10362229574678217</td><td>106.19326795531998</td><td>81.73599148245327</td><td>-10.20633132785529</td><td>0.778051495552063</td><td>0.5637893944151302</td><td>-0.2770873032260318</td><td>-0.2447324288495145</td><td>-0.13420077738774477</td><td>-0.960258397317067</td><td>-0.57856883180264</td><td>0.8149427403772278</td><td>0.0335624309754635</td><td>28.03821793521729</td><td>22.953089681994513</td><td>-3.2529257228048234</td><td>0.8548998832702637</td><td>0.47899385711488035</td><td>-0.19927645448558487</td><td>-0.37472315456571015</td><td>0.3044741498035521</td><td>-0.8757157355750365</td><td>-0.35878792886391675</td><td>0.8233227659597501</td><td>0.4397849987822771</td><td>9.766195040270658</td><td>8.692339146168745</td><td>5.119134099857715</td><td>0.8400160074234009</td><td>0.20962384116815538</td><td>0.5004307851097664</td><td>-0.5422037651656503</td><td>0.3578287100487087</td><td>0.7602458097911947</td><td>0.019702855424065132</td><td>0.9099540974570008</td><td>-0.41424067643020446</td><td>2.3679617471799905</td><td>2.1642857947847527</td><td>1.5947039668881267</td><td>11.115723647777203</td><td>0.0</td><td>137.8258819580078</td><td>12.095911876887975</td><td>0.0</td><td>38878.03515625</td><td>849.0914306640625</td><td>26326.99609375</td><td>18306.93359375</td><td>1.4113867282867432</td><td>26.66329574584961</td><td>17.27666473388672</td><td>-0.6442798631117556</td><td>0.13761416014325387</td><td>0.7523069858221204</td><td>0.7423171156837277</td><td>-0.12418326258128562</td><td>0.6584404430604626</td><td>-0.18403466453820141</td><td>-0.9826702703464344</td><td>0.02214457101813702</td><td>0.03617064514392236</td><td>0.0322852986267902</td><td>0.028433050752495505</td><td>-0.487853080034256</td><td>-0.006067287176847458</td><td>0.6665339469909668</td></tr>\n",
       "<tr><td>8.0</td><td>0.012384133540565926</td><td>0.011480578764441723</td><td>0.008352121662922892</td><td>-0.09489200944034107</td><td>0.9845018255922565</td><td>-0.14748444646771572</td><td>-0.6070729329106967</td><td>-0.1746455075092532</td><td>-0.7752170024154785</td><td>0.7889600501112708</td><td>-0.015971916364344224</td><td>-0.6142368738655077</td><td>0.7868995070457458</td><td>0.6145145813034041</td><td>0.05622298256882669</td><td>0.6145898622580878</td><td>-0.7886416891792428</td><td>0.017988532405250793</td><td>0.05539400340305002</td><td>0.020398908157355643</td><td>-0.9982561740019295</td><td>297.00356951122933</td><td>154.70036110379576</td><td>106.36466728451252</td><td>-0.9773894548416138</td><td>-0.19233808125036161</td><td>-0.08784018444010429</td><td>0.20084339955830172</td><td>-0.9743790274684</td><td>-0.10122963836544814</td><td>-0.06611931907851548</td><td>-0.11658290325199669</td><td>0.9909776295729025</td><td>45.70994895845578</td><td>41.547306769246795</td><td>14.042110243323462</td><td>0.9484310746192932</td><td>-0.21409147544254528</td><td>0.23375905418496223</td><td>-0.25863785674287965</td><td>-0.9490173863896809</td><td>0.18020116367423786</td><td>0.1832618736400553</td><td>-0.2313673280152882</td><td>-0.9554497606870821</td><td>12.333956344572897</td><td>10.806718608133647</td><td>7.680217240448437</td><td>0.8317590355873108</td><td>-0.28411894710134616</td><td>0.4769206318809015</td><td>-0.5212707518563224</td><td>-0.695197018785786</td><td>0.4949524303713436</td><td>0.19092843809867752</td><td>-0.6602859448522115</td><td>-0.7263393164050955</td><td>2.5267100202069264</td><td>2.377367265966651</td><td>1.7441043594413514</td><td>11.179423297769437</td><td>0.0</td><td>118.54483032226562</td><td>12.014287134223032</td><td>0.0</td><td>38878.03515625</td><td>849.0914306640625</td><td>26326.99609375</td><td>18306.93359375</td><td>0.8358985781669617</td><td>26.50518798828125</td><td>17.452577590942383</td><td>0.03019337371364592</td><td>-0.9973178994724258</td><td>0.06667358979158695</td><td>0.6088277874201042</td><td>0.0712522137829101</td><td>0.7900961000385804</td><td>0.7927276237453368</td><td>-0.016737067334008347</td><td>-0.6093461948089348</td><td>0.02507435545710483</td><td>0.023336459324641515</td><td>0.017664686905375673</td><td>-0.478249192237854</td><td>0.572478175163269</td><td>0.7418162822723389</td></tr>\n",
       "<tr><td>9.0</td><td>0.011825359956376158</td><td>0.010521218654665525</td><td>0.008978701775802936</td><td>-0.7609710684566479</td><td>-0.6463192607270818</td><td>0.05651943192518953</td><td>0.3723984291927872</td><td>-0.3637957790608959</td><td>0.8537985951453777</td><td>-0.5312649460548777</td><td>0.670763776862372</td><td>0.5175263401437973</td><td>0.411751389503479</td><td>-0.8524676327996239</td><td>0.3221175630061307</td><td>-0.4447841681946456</td><td>0.12051648053501705</td><td>0.8874924346961213</td><td>0.7953790499449934</td><td>0.5086990396574953</td><td>0.3295412780823392</td><td>267.7468038439064</td><td>172.7403347699184</td><td>-32.640283025697485</td><td>0.7494412660598755</td><td>0.6344754920526042</td><td>-0.18915235918686385</td><td>-0.43950295814616697</td><td>0.26309741857929136</td><td>-0.8588462598845511</td><td>0.49515140591754225</td><td>-0.7267878633559586</td><td>-0.47602992226997876</td><td>49.09953130616094</td><td>41.87076494607203</td><td>29.394175175203834</td><td>0.8856460452079773</td><td>0.3705045218806867</td><td>-0.2799240623581826</td><td>-0.29344113471123306</td><td>0.9137431830026912</td><td>0.28100835570405097</td><td>0.3598935702128169</td><td>-0.16673270459653186</td><td>0.9179743042903749</td><td>12.130659111205967</td><td>11.040164845071411</td><td>9.127062973829954</td><td>0.8107178211212158</td><td>0.3727685313728518</td><td>-0.4514201993941928</td><td>-0.5305426667923021</td><td>0.7938056589848028</td><td>-0.2973164214714939</td><td>0.24750970307419756</td><td>0.4805374051848933</td><td>0.8413220246150055</td><td>2.4672608847176476</td><td>2.348442180176855</td><td>1.8129556375128915</td><td>11.1342911848653</td><td>0.0</td><td>129.09141540527344</td><td>12.062344157286425</td><td>0.0</td><td>38878.03515625</td><td>849.0914306640625</td><td>26326.99609375</td><td>18306.93359375</td><td>0.4719037413597107</td><td>26.57210350036621</td><td>18.048410415649414</td><td>-0.010990762544732776</td><td>-0.937025356616335</td><td>0.34908836158874756</td><td>0.8748738199638653</td><td>0.16004706438643404</td><td>0.45714410892312607</td><td>-0.4842261891724978</td><td>0.31043263075797217</td><td>0.8180199138652835</td><td>0.03507434720214762</td><td>0.027104034426882407</td><td>0.02378750381252945</td><td>-0.7521599531173706</td><td>0.16906972229480743</td><td>0.4688679873943329</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>752194.0</td><td>0.0039049782377542867</td><td>0.0036617101517045876</td><td>0.00323593098287949</td><td>-0.8969425341511473</td><td>0.15923472866925656</td><td>0.41247835290612045</td><td>0.4385604363122114</td><td>0.20181889799140837</td><td>0.8757476098255571</td><td>-0.056203506404498144</td><td>-0.9663919668535962</td><td>0.25085400588525136</td><td>0.8813514113426208</td><td>-0.14239274624984932</td><td>-0.45049302620831444</td><td>-0.454290413917188</td><td>0.006483625748448637</td><td>-0.8908300524904308</td><td>0.1297685658002307</td><td>0.9897890019658634</td><td>-0.05897330682241867</td><td>5.970796756331006</td><td>3.5133344809792804</td><td>-2.9648340086428737</td><td>-0.87455153465271</td><td>-0.055496988388769694</td><td>-0.4817465506771193</td><td>0.45307553636173487</td><td>0.2606185793915024</td><td>-0.8525259611451617</td><td>-0.17286472503102496</td><td>0.9638454442262679</td><td>0.20278004459072446</td><td>3.5582254513528113</td><td>1.9449147384840677</td><td>-3.678877401717923</td><td>-0.8715538382530212</td><td>-0.09990647198693227</td><td>0.4800131555179455</td><td>0.40938610145545484</td><td>0.3904636323890103</td><td>0.8245854544658691</td><td>-0.2698091039054739</td><td>0.9151813200872844</td><td>-0.2994097506979705</td><td>2.484524160636765</td><td>1.2301506411263117</td><td>-1.137547397261705</td><td>0.7137887477874756</td><td>0.5192677404498717</td><td>-0.46996452723553467</td><td>-0.14948485572206624</td><td>-0.5426113854083702</td><td>-0.8265755635965549</td><td>0.684222128435925</td><td>-0.6602529046912965</td><td>0.30968723061391806</td><td>1.0579058050113466</td><td>0.6455042915192071</td><td>0.11860523604323951</td><td>9.37953818788658</td><td>34218.0</td><td>2.0303726196289062</td><td>10.253033549677326</td><td>1.0</td><td>2.135425329208374</td><td>43591.21875</td><td>66893.1015625</td><td>46197.33203125</td><td>43.591217041015625</td><td>66.89310455322266</td><td>46.197330474853516</td><td>-0.33428342418923335</td><td>-0.5364417851953097</td><td>0.7749095453075738</td><td>0.8781455882307229</td><td>-0.4758345354840794</td><td>0.049414782318335675</td><td>-0.3422205694917228</td><td>-0.69700194112866</td><td>-0.6301375848809855</td><td>0.009796140220580327</td><td>0.00909373617652982</td><td>0.008591940835305619</td><td>-0.9059203267097473</td><td>-0.27984654903411865</td><td>0.3170780837535858</td></tr>\n",
       "<tr><td>752818.0</td><td>0.0026186262605587193</td><td>0.0024932728331082256</td><td>0.002279924441617432</td><td>-0.9030752217638134</td><td>-0.42804347083864136</td><td>-0.03512735271335533</td><td>-0.37217532460122005</td><td>0.7391351649699659</td><td>0.561395347026316</td><td>-0.21433775121106394</td><td>0.5200557614114376</td><td>-0.8268018707214889</td><td>-0.20766738057136536</td><td>-0.6820985198038517</td><td>0.7011532425744401</td><td>0.5806113379797836</td><td>0.4909114048286273</td><td>0.6495355777927098</td><td>0.7872513794847126</td><td>-0.5419848723816729</td><td>-0.2940878501550836</td><td>11.468423455048686</td><td>10.651956184244154</td><td>-9.081636927805297</td><td>-0.2167843133211136</td><td>-0.9318600698414162</td><td>-0.2909319059122004</td><td>0.5927500302742935</td><td>-0.36244097476253795</td><td>0.7192245417274118</td><td>0.7756622752541074</td><td>0.016533301192812565</td><td>-0.6309316006504104</td><td>5.571626128709312</td><td>5.305849647593844</td><td>-1.665199122983732</td><td>-0.0744098424911499</td><td>-0.7523948560910872</td><td>0.6544961084557119</td><td>0.5978332116983757</td><td>0.49164441112732254</td><td>0.6331518174953567</td><td>0.798159524435062</td><td>-0.43839223708334535</td><td>-0.41322345047039083</td><td>1.7220040774830347</td><td>1.5588226742413658</td><td>0.7511200728909818</td><td>0.44135501980781555</td><td>-0.5377206255924155</td><td>0.7183747397692141</td><td>0.18492605354786965</td><td>0.8378870880291757</td><td>0.5135636108927497</td><td>0.8780706649496923</td><td>0.09381767704697398</td><td>-0.4692442336654916</td><td>0.38305216297663175</td><td>0.3019758838822295</td><td>0.19838676700390007</td><td>9.16511860248219</td><td>34416.0</td><td>2.374236822128296</td><td>10.347829465651081</td><td>1.0</td><td>2.6618595123291016</td><td>22884.365234375</td><td>24484.498046875</td><td>55708.71875</td><td>22.88436508178711</td><td>24.484498977661133</td><td>55.708717346191406</td><td>-0.74311389551055</td><td>-0.6587438549240829</td><td>-0.11763618447949593</td><td>0.4915361967780833</td><td>-0.41806821367418684</td><td>-0.7639444586959265</td><td>-0.4540637681604565</td><td>0.6255201853777647</td><td>-0.6344687479528792</td><td>0.009999610624272874</td><td>0.008407642147943567</td><td>0.00785384932863061</td><td>-0.7071279287338257</td><td>0.4234252870082855</td><td>-0.11567516624927521</td></tr>\n",
       "<tr><td>755536.0</td><td>0.0021613513097696055</td><td>0.00207422701044982</td><td>0.0019470556776861182</td><td>0.5680242291524903</td><td>-0.12896409205728354</td><td>-0.8128448425471861</td><td>-0.716978955399259</td><td>-0.5624660205781143</td><td>-0.4117926094645316</td><td>0.4040911439394667</td><td>-0.8167008256729397</td><td>0.41195886777059687</td><td>-0.3111162781715393</td><td>-0.9457294025660034</td><td>-0.093821912995568</td><td>0.700595806725478</td><td>-0.29493411861908686</td><td>0.6497533234028579</td><td>-0.6421621055735647</td><td>0.1364176044230847</td><td>0.7543328624478672</td><td>17.2170062071065</td><td>12.974222181701856</td><td>-16.882677835225092</td><td>0.3025914430618286</td><td>0.9404595212832804</td><td>-0.15483640782516903</td><td>-0.691771241037885</td><td>0.32845478490129515</td><td>0.6430940866998766</td><td>0.6556607159449793</td><td>-0.08748338758340188</td><td>0.749970454393671</td><td>10.921497738375654</td><td>7.986124265775706</td><td>-10.690819231498974</td><td>-0.4161469042301178</td><td>0.8774404260381898</td><td>-0.2385792142164934</td><td>0.6614251737142258</td><td>0.47214744851157725</td><td>0.5827465370477234</td><td>-0.6239699369996484</td><td>-0.08470587711562799</td><td>0.7768438917200332</td><td>6.391702243933468</td><td>5.435520623703876</td><td>-1.974914627062353</td><td>0.5831827521324158</td><td>-0.36280727781932565</td><td>-0.7268210102950337</td><td>-0.6401639153442851</td><td>0.3455485194849024</td><td>-0.6861387484852224</td><td>0.5000880555822523</td><td>0.8654288531376353</td><td>-0.03073819807404793</td><td>2.0490855478253582</td><td>1.9420036362058934</td><td>0.7419671860135247</td><td>9.270321659484827</td><td>35267.0</td><td>2.1864006519317627</td><td>10.300821641305507</td><td>1.0</td><td>2.3315136432647705</td><td>2042.494140625</td><td>25050.94921875</td><td>18758.775390625</td><td>2.042494058609009</td><td>25.050949096679688</td><td>18.75877571105957</td><td>-0.3263830133088009</td><td>-0.8374746126016356</td><td>0.43830400622308613</td><td>0.8027756152309624</td><td>-0.0007882010487470872</td><td>0.5962807143700495</td><td>0.49902448859150866</td><td>-0.5464756645879546</td><td>-0.6725614528049734</td><td>0.005858898899447545</td><td>0.005688195098892562</td><td>0.0056594885769899106</td><td>-0.9588258862495422</td><td>0.663828432559967</td><td>-0.3421096205711365</td></tr>\n",
       "<tr><td>755674.0</td><td>0.004436804083140114</td><td>0.004264740110807067</td><td>0.0025533748600972766</td><td>0.04403848197702088</td><td>-0.1135546899290897</td><td>-0.9925552601746</td><td>0.9505702597764065</td><td>-0.30091247648105296</td><td>0.07660197599706549</td><td>-0.30737077501573706</td><td>-0.9468669462459592</td><td>0.0946899824325525</td><td>-0.11105625331401825</td><td>0.9927880217499921</td><td>0.045149222326187496</td><td>-0.3622912634031452</td><td>-0.08274732416115264</td><td>0.9283845759198729</td><td>-0.9254250638861452</td><td>-0.08674574464436825</td><td>-0.3688680345562874</td><td>13.95188110612573</td><td>11.187302298978205</td><td>-19.386835812314224</td><td>0.16068865358829498</td><td>-0.978925184570336</td><td>0.1260342872967807</td><td>0.37727176411351526</td><td>0.17891567899753882</td><td>0.9086557080718338</td><td>0.9120554668237838</td><td>0.09846147887769592</td><td>-0.3980705497949664</td><td>11.8258019368186</td><td>9.33140442632036</td><td>-11.99921107508282</td><td>0.2940555512905121</td><td>-0.9373061462802995</td><td>0.18705217230597665</td><td>0.3416856022786474</td><td>0.2858612009989778</td><td>0.895284492750154</td><td>0.8926266163490134</td><td>0.19935034965757129</td><td>-0.40432309095167346</td><td>6.167059663873896</td><td>5.286718570452355</td><td>-0.206161498032284</td><td>0.2879871726036072</td><td>-0.8555263496191945</td><td>0.4302767120814721</td><td>0.29795075684016564</td><td>0.5070595174306202</td><td>0.8087743766226767</td><td>0.9101036920872033</td><td>0.10471538039028457</td><td>-0.4009313641497244</td><td>1.6106905869774604</td><td>1.4610559910002954</td><td>0.8732351221659276</td><td>9.021579218125245</td><td>35311.0</td><td>2.6895902156829834</td><td>10.412375827861602</td><td>1.0</td><td>2.8207802772521973</td><td>41948.828125</td><td>67385.875</td><td>43157.11328125</td><td>41.948829650878906</td><td>67.38587188720703</td><td>43.15711212158203</td><td>-0.7932919083736172</td><td>-0.10996820093798011</td><td>-0.5988279743727813</td><td>0.5489113093915441</td><td>-0.5547038022661512</td><td>-0.6252999809479729</td><td>0.2634090403365174</td><td>0.8247488627054532</td><td>-0.5004048270501155</td><td>0.011458019378859392</td><td>0.01017745813650446</td><td>0.00940806951299503</td><td>-0.996257483959198</td><td>-0.08073781430721283</td><td>0.3829881250858307</td></tr>\n",
       "<tr><td>756143.0</td><td>0.00308361038690644</td><td>0.002863228393033827</td><td>0.0026574845332567217</td><td>-0.8820282465768073</td><td>-0.30503057593444066</td><td>-0.3591413649048887</td><td>0.37735646811831136</td><td>-0.913722593613067</td><td>-0.15070871869365546</td><td>-0.28218481215316443</td><td>-0.2684536639089007</td><td>0.9210343979048611</td><td>0.0015297271311283112</td><td>0.6829034495813674</td><td>0.7305070420501512</td><td>-0.5062166100096855</td><td>0.630523231567244</td><td>-0.5883750489307832</td><td>0.8624050113985278</td><td>0.3688947451562144</td><td>-0.34666159768690435</td><td>10.484103245714167</td><td>9.364777762883662</td><td>-10.484911472825559</td><td>0.0693657174706459</td><td>0.6393084073479804</td><td>0.7658153546009777</td><td>-0.5144573365815175</td><td>0.6806359637661176</td><td>-0.5216017002135052</td><td>0.8547058241792225</td><td>0.3577980507525953</td><td>-0.37610970340016375</td><td>9.155412621463178</td><td>7.249615957388292</td><td>-9.763320299917943</td><td>0.11723411083221436</td><td>-0.664608436684243</td><td>-0.7379375237218778</td><td>-0.45003975370358634</td><td>-0.6979383065317145</td><td>0.5570873722873798</td><td>0.8852798332251028</td><td>-0.26679157813500975</td><td>0.38092239461754607</td><td>5.8597562089345825</td><td>4.904736729885101</td><td>-3.0848186345156816</td><td>0.1956349015235901</td><td>-0.7960476172685534</td><td>-0.5727435517287517</td><td>-0.32617973240589426</td><td>-0.6035965775051984</td><td>0.7275149165423553</td><td>0.9248425634525186</td><td>-0.044490028827478094</td><td>0.3777391562460853</td><td>2.021503591285496</td><td>1.8367751552424527</td><td>0.21233276768052678</td><td>9.07359434300567</td><td>35460.0</td><td>2.484553813934326</td><td>10.374030833319939</td><td>1.0</td><td>2.7357537746429443</td><td>12748.4169921875</td><td>49639.87890625</td><td>47643.5</td><td>12.748416900634766</td><td>49.63987731933594</td><td>47.64350128173828</td><td>-0.955188023683456</td><td>0.29030062106486715</td><td>-0.057804747391940074</td><td>0.26884812485837184</td><td>0.932570293718068</td><td>0.24090108558230686</td><td>-0.12384072501334462</td><td>-0.2145651338963279</td><td>0.9688267534209717</td><td>0.00968518309011414</td><td>0.008876370829769229</td><td>0.008005922377726408</td><td>-0.8064053058624268</td><td>0.02114914357662201</td><td>0.5130857229232788</td></tr>\n",
       "<tr><td>759874.0</td><td>0.002820744583448637</td><td>0.002662717462739102</td><td>0.002319225147659849</td><td>0.04319607310607816</td><td>-0.9530069040905351</td><td>0.2998531974550014</td><td>-0.6074539930611559</td><td>0.2132287320806834</td><td>0.7652013814214669</td><td>0.7931795166179414</td><td>0.2152007169389496</td><td>0.5696972054053719</td><td>-0.1481405794620514</td><td>-0.82326837452263</td><td>-0.5479813409441071</td><td>0.67024069836565</td><td>-0.49101434161756335</td><td>0.5564910804138702</td><td>0.7272082045510493</td><td>0.2848404813869292</td><td>-0.6245271230274163</td><td>7.30261618068809</td><td>6.609193025087626</td><td>-6.649047371244596</td><td>0.22049525380134583</td><td>-0.6521221977135423</td><td>0.7253402541486638</td><td>-0.6843301402915557</td><td>-0.6333280678775361</td><td>-0.3613693644002592</td><td>-0.6950353258128171</td><td>0.41669196979035555</td><td>0.5859127052594989</td><td>5.071516011979067</td><td>4.657164687021211</td><td>-4.639407350910298</td><td>0.22362379729747772</td><td>0.36972846819821875</td><td>0.9018277329587392</td><td>-0.7103837628876122</td><td>0.6953354972725315</td><td>-0.10891949163670296</td><td>-0.6673434719507917</td><td>-0.6162867887895698</td><td>0.4181426603542181</td><td>2.510227887296019</td><td>2.4446278380397635</td><td>-0.29550932599063673</td><td>-0.33222824335098267</td><td>0.0033420409483209644</td><td>0.9431930972938731</td><td>0.7715653706591196</td><td>-0.5742085519298509</td><td>0.27380908986057984</td><td>0.5425046237776824</td><td>0.8187022472504417</td><td>0.1881897009055279</td><td>0.7182822949657577</td><td>0.6025217404174937</td><td>0.2306177146392478</td><td>9.066625113181685</td><td>36674.0</td><td>2.4078431129455566</td><td>10.360074871278913</td><td>1.0</td><td>2.522681713104248</td><td>56744.86328125</td><td>8870.302734375</td><td>35271.48046875</td><td>56.7448616027832</td><td>8.8703031539917</td><td>35.271480560302734</td><td>-0.49254175439093084</td><td>-0.7410512703662206</td><td>-0.4563393856222735</td><td>-0.3426860771911116</td><td>-0.31684952479878653</td><td>0.8844052414669142</td><td>-0.7999805451889888</td><td>0.5919876631513475</td><td>-0.09788633201696292</td><td>0.010622851462192457</td><td>0.00982369881825927</td><td>0.009650462343434934</td><td>-0.8629167675971985</td><td>0.048090964555740356</td><td>-0.16218844056129456</td></tr>\n",
       "<tr><td>765609.0</td><td>0.004260902628739046</td><td>0.0034987491021631826</td><td>0.0034106950579482743</td><td>-0.7254811450662946</td><td>-0.29035294328760564</td><td>-0.6239970164011381</td><td>-0.6037416947992897</td><td>-0.1667834636273663</td><td>0.7795378388643749</td><td>0.33041348960685485</td><td>-0.9422730201935549</td><td>0.05429991989991641</td><td>0.39381176233291626</td><td>-0.6548285431766336</td><td>-0.6450673468188927</td><td>-0.2761178421602759</td><td>-0.7536412095371603</td><td>0.5964762061709743</td><td>0.8767389806159819</td><td>0.05678473675674944</td><td>0.47760261048272723</td><td>10.481565932624203</td><td>6.6920962085506615</td><td>-7.170262658610948</td><td>0.4483642280101776</td><td>-0.8762701314169516</td><td>-0.17640911969134018</td><td>-0.19613505366352707</td><td>-0.28899686470826963</td><td>0.9370228668037912</td><td>0.87206683313159</td><td>0.38552752038642946</td><td>0.30144314484912554</td><td>4.729470471816316</td><td>4.465591796277699</td><td>-0.3970924795654311</td><td>0.48078492283821106</td><td>0.7879133844221842</td><td>-0.38475751826720556</td><td>-0.000794233791429596</td><td>-0.4384093620450877</td><td>-0.8987750555416539</td><td>0.8768381939716388</td><td>-0.4324230913348613</td><td>0.21015482786021653</td><td>1.7567807726870621</td><td>1.426349191737206</td><td>0.2031151300820342</td><td>0.4790285527706146</td><td>0.7892295986942002</td><td>-0.3842502908566294</td><td>0.13989461687933577</td><td>-0.5007876366108205</td><td>-0.8541903998441644</td><td>0.8665801415025594</td><td>-0.35542704393833213</td><td>0.3503005492297478</td><td>0.682993241841505</td><td>0.39078392445802157</td><td>-0.28050173093942027</td><td>9.166164408100107</td><td>38584.0</td><td>1.9691458940505981</td><td>10.260569774889639</td><td>1.0</td><td>2.1477677822113037</td><td>69493.40625</td><td>24621.359375</td><td>14227.939453125</td><td>69.493408203125</td><td>24.62135887145996</td><td>14.22793960571289</td><td>-0.6743944499030639</td><td>-0.010403297096392141</td><td>-0.7382979732800758</td><td>-0.717860103919018</td><td>-0.22480331505028345</td><td>0.6588932696148744</td><td>0.17282649432688355</td><td>-0.9743486239287901</td><td>-0.1441379960550045</td><td>0.010279716595123521</td><td>0.008949812636168017</td><td>0.008544749853599294</td><td>-0.6449933052062988</td><td>-0.14330190420150757</td><td>0.025591935962438583</td></tr>\n",
       "<tr><td>768819.0</td><td>0.0021323759568082227</td><td>0.0019531829151296413</td><td>0.00168196992926417</td><td>0.22650844435540055</td><td>0.8825824324248946</td><td>0.4119977847157102</td><td>0.22960971113889792</td><td>0.36268625898340107</td><td>-0.9031821843323399</td><td>0.9465586644188557</td><td>-0.299177083881071</td><td>0.12049799705393582</td><td>0.5274119973182678</td><td>0.05384076766902656</td><td>-0.8479019808409981</td><td>-0.8137323925258569</td><td>0.3189620539130704</td><td>-0.4859041073274638</td><td>0.24428710717396201</td><td>0.9462369575853424</td><td>0.21203638689671114</td><td>19.25813556124239</td><td>5.157875753926299</td><td>-12.949636135332824</td><td>-0.30958840250968933</td><td>0.22900413062259264</td><td>0.9228825088615509</td><td>0.8808795210692636</td><td>-0.2964034887415335</td><td>0.3690477492447729</td><td>0.3580590542991266</td><td>0.9272012079476807</td><td>-0.1099619644003186</td><td>10.042317755658667</td><td>4.536471533194636</td><td>-2.1186116933800037</td><td>-0.13278178870677948</td><td>-0.28319771340635713</td><td>0.9498252751686096</td><td>0.5369329413552438</td><td>0.7849578247187383</td><td>0.3091022968216713</td><td>0.8331098455277792</td><td>-0.5510356327264482</td><td>-0.047830082066023676</td><td>4.374354019368073</td><td>2.568492555061436</td><td>1.041868943709825</td><td>-0.021763809025287628</td><td>-0.18826020958231326</td><td>0.9818780118442816</td><td>0.1488672411019617</td><td>0.9705517113362551</td><td>0.18938827880562378</td><td>0.9886176617792873</td><td>-0.1502912808857845</td><td>-0.006902876774547467</td><td>1.1737398506529195</td><td>1.0210257779570981</td><td>0.46605677495209324</td><td>9.060861714881428</td><td>39684.0</td><td>1.8780118227005005</td><td>10.23730285922426</td><td>1.0</td><td>2.0431861877441406</td><td>36158.20703125</td><td>74774.9453125</td><td>70913.0546875</td><td>36.158206939697266</td><td>74.77494812011719</td><td>70.91305541992188</td><td>-0.25880737812234933</td><td>0.5373878123052639</td><td>-0.8026413147945962</td><td>0.9001275221184105</td><td>-0.16727014441858473</td><td>-0.4022326972178621</td><td>0.35041287783756714</td><td>0.8265803275979584</td><td>0.4404268123918498</td><td>0.007447231116267198</td><td>0.006435803850254935</td><td>0.005884069490372308</td><td>-0.7623950839042664</td><td>-0.16326552629470825</td><td>-0.24580833315849304</td></tr>\n",
       "<tr><td>770944.0</td><td>0.003327517241708196</td><td>0.002747715967309195</td><td>0.002407341366642528</td><td>0.14292035662607</td><td>0.6694683238880966</td><td>0.72896223151295</td><td>-0.5992812437275111</td><td>-0.5276248767513952</td><td>0.6020581204082236</td><td>-0.7876774483113533</td><td>0.522899754009827</td><td>-0.3257914742257349</td><td>0.05435025691986084</td><td>0.7641332931650193</td><td>0.6427646223097467</td><td>0.9839356278544618</td><td>0.06864069457954995</td><td>-0.16480028909648037</td><td>0.1700491977483439</td><td>-0.6413959505051615</td><td>0.7481273320904169</td><td>16.031065234256847</td><td>13.097033127661414</td><td>-18.57526951137799</td><td>0.042064864188432693</td><td>0.5122840869476556</td><td>-0.8577852652925486</td><td>0.9745662965674106</td><td>0.16810868869776616</td><td>0.1481890764503211</td><td>0.22011606185756488</td><td>-0.8422021628115925</td><td>-0.49218333603220676</td><td>8.338396006391417</td><td>7.324287751073336</td><td>-2.9798515915973374</td><td>-0.08957286179065704</td><td>-0.5715592807471986</td><td>-0.8156572142414509</td><td>0.8270799596506596</td><td>-0.49895586369803363</td><td>0.25880839713118475</td><td>0.5549012911290102</td><td>0.6514315272329814</td><td>-0.5174181311379249</td><td>2.724508155446739</td><td>1.8929122368676128</td><td>1.1767791243203767</td><td>-0.5422424077987671</td><td>-0.4646034656564396</td><td>-0.7000834361301348</td><td>0.09872729271140354</td><td>-0.8626714405853982</td><td>0.4960351875343029</td><td>0.8344016535923378</td><td>-0.19985395992659125</td><td>-0.5136460602243853</td><td>0.7937468924310519</td><td>0.47057788766000547</td><td>0.06254334276224803</td><td>9.061394550156637</td><td>40428.0</td><td>1.8275648355484009</td><td>10.233600190108088</td><td>1.0</td><td>2.186333417892456</td><td>23255.451171875</td><td>67403.6328125</td><td>73682.65625</td><td>23.255451202392578</td><td>67.40363311767578</td><td>73.68265533447266</td><td>-0.029873393774191622</td><td>0.959348917237283</td><td>0.28063719521842584</td><td>0.9545157855163463</td><td>-0.055948303086403764</td><td>0.29286413672873035</td><td>0.2966600673237379</td><td>0.2766214785178561</td><td>-0.9140423196319035</td><td>0.010272358832846969</td><td>0.008207857856765633</td><td>0.007920067444851958</td><td>-0.7486265897750854</td><td>0.3115461468696594</td><td>0.6876575946807861</td></tr>\n",
       "<tr><td>803349.0</td><td>0.0031508121209186802</td><td>0.0030230735357601266</td><td>0.0021085432756289216</td><td>-0.32068781961542403</td><td>0.8583297912918535</td><td>0.4005362552019344</td><td>0.11450726335093839</td><td>0.4549004614612307</td><td>-0.8831498495738073</td><td>0.9402379533874308</td><td>0.23735108919750747</td><td>0.24416603258146458</td><td>-0.653459370136261</td><td>-0.6424877035768541</td><td>0.40025042264332955</td><td>0.5947728860507294</td><td>-0.10873011102233433</td><td>0.7965067337919722</td><td>-0.46822650938675986</td><td>0.7585428885103405</td><td>0.4531849756974288</td><td>6.6748121996964525</td><td>2.1377852490317872</td><td>-5.148943097278041</td><td>0.7105637788772583</td><td>-0.5531318755114786</td><td>-0.4349071783190374</td><td>-0.484342016331643</td><td>0.06385517200989986</td><td>-0.8725453158566515</td><td>0.5104036997084477</td><td>0.8306429108231407</td><td>-0.2225318359767618</td><td>4.223898005240051</td><td>2.4463229500904813</td><td>-2.6088281377861557</td><td>-0.7002483010292053</td><td>-0.4427910772855235</td><td>0.5599896365228617</td><td>0.42053104198821856</td><td>0.37802810777223383</td><td>0.8247717214226297</td><td>-0.5768933817101604</td><td>0.8130380136318779</td><td>-0.07850614325354002</td><td>2.4838324889453736</td><td>1.8398044371683278</td><td>-1.1980335771197033</td><td>-0.641701877117157</td><td>-0.4435216393631488</td><td>0.6257054349642287</td><td>0.3951264139991685</td><td>0.5080488462491738</td><td>0.7653505646336464</td><td>-0.65733846143924</td><td>0.7383596178296242</td><td>-0.15076876954855106</td><td>0.9848531553910784</td><td>0.7312008380597477</td><td>0.03994652212845551</td><td>9.022659705093925</td><td>52574.0</td><td>1.3310412168502808</td><td>10.087959106730207</td><td>1.0</td><td>1.3615388870239258</td><td>45466.94140625</td><td>36893.8515625</td><td>72491.796875</td><td>45.466941833496094</td><td>36.89385223388672</td><td>72.4917984008789</td><td>-0.38634791225497644</td><td>0.18658681399575996</td><td>0.9032832620718336</td><td>-0.34642264167820824</td><td>0.8782718458782803</td><td>-0.3295905309171525</td><td>0.8548255050177862</td><td>0.44025438734948485</td><td>0.27468059704066633</td><td>0.007025950808725896</td><td>0.006659610929452984</td><td>0.006428501890477896</td><td>-0.2274145483970642</td><td>-0.12203589081764221</td><td>0.053576335310935974</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=17457>\n",
       " gal_id            a           ...        mlp_av_y             mlp_av_z      \n",
       "float64         float64        ...        float64              float64       \n",
       "-------- --------------------- ... --------------------- --------------------\n",
       "     0.0   0.24562844247483243 ...      0.51895672082901   0.5298088788986206\n",
       "     1.0   0.08088470650058953 ...   -0.5722015500068665   0.8127713799476624\n",
       "     2.0  0.029657668413294556 ...   -0.1834503561258316   0.2371581792831421\n",
       "     3.0  0.018082525231503666 ...  -0.13807687163352966  0.38148462772369385\n",
       "     4.0   0.01801164473834766 ...   0.06337937712669373   0.3301573693752289\n",
       "     5.0  0.020714045769373805 ...    0.2240697145462036  0.34571993350982666\n",
       "     6.0  0.014119734858107792 ...    0.1805431842803955   0.8364304900169373\n",
       "     7.0  0.014264607282143125 ... -0.006067287176847458   0.6665339469909668\n",
       "     8.0  0.012384133540565926 ...     0.572478175163269   0.7418162822723389\n",
       "     9.0  0.011825359956376158 ...   0.16906972229480743   0.4688679873943329\n",
       "     ...                   ... ...                   ...                  ...\n",
       "752194.0 0.0039049782377542867 ...  -0.27984654903411865   0.3170780837535858\n",
       "752818.0 0.0026186262605587193 ...    0.4234252870082855 -0.11567516624927521\n",
       "755536.0 0.0021613513097696055 ...     0.663828432559967  -0.3421096205711365\n",
       "755674.0  0.004436804083140114 ...  -0.08073781430721283   0.3829881250858307\n",
       "756143.0   0.00308361038690644 ...   0.02114914357662201   0.5130857229232788\n",
       "759874.0  0.002820744583448637 ...  0.048090964555740356 -0.16218844056129456\n",
       "765609.0  0.004260902628739046 ...  -0.14330190420150757 0.025591935962438583\n",
       "768819.0 0.0021323759568082227 ...  -0.16326552629470825 -0.24580833315849304\n",
       "770944.0  0.003327517241708196 ...    0.3115461468696594   0.6876575946807861\n",
       "803349.0 0.0031508121209186802 ...  -0.12203589081764221 0.053576335310935974"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e296451",
   "metadata": {},
   "source": [
    "## Let's build the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a62847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_key='GroupID'\n",
    "pos_key=['gal_pos_x', 'gal_pos_y', 'gal_pos_z']\n",
    "scalar_key = ['mass', 'dm_mass']\n",
    "catalog = tng\n",
    "\n",
    "# It takes a minute but we precompute all the graphs and data\n",
    "# Identify the individual groups and pre-extract the relevant data\n",
    "\n",
    "group_ids = catalog[group_key].astype(jnp.int32)\n",
    "gids, idx = jnp.unique(group_ids, return_index=True) # gids are the unique group ids, in other words All the host halo IDS uniquely  extracted     idx = The indices of the first occurrences of the unique values in the original array. i.e index of the central galaxy\n",
    "Position = jnp.array(catalog[pos_key].to_pandas())\n",
    "Scalars = jnp.array(catalog[scalar_key].to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "091471bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_radius = 1 #Mpc/h\n",
    "graphs_list = []\n",
    "node_features_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de74b5ed-3dae-4a49-bbc6-c8f91b3e5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for gid in gids:\n",
    "    \n",
    "    g = np.where(group_ids == gid)[0]\n",
    "    Positions_for_group = Position[g]\n",
    "    Features_for_group = Scalars[g]\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    # Compute adjacency matrix for each entry\n",
    "    graph = radius_neighbors_graph(Positions_for_group, graph_radius, mode='connectivity',\n",
    "                               include_self=False)\n",
    "    graphs_list.append(graph)\n",
    "    node_features_list.append(Features_for_group)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe1349e",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39f81f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_node = graphs_list[0].tocoo().shape[0]\n",
    "max_n_edge = graphs_list[0].tocoo().nnz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1a869f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_n_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "babd3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "senders_list = []\n",
    "receivers_list = []\n",
    "n_node_list = []\n",
    "n_edge_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62db2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12261171",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10292/10292 [00:13<00:00, 740.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for single_graph in tqdm(graphs_list):\n",
    "    single_graph =  single_graph.tocoo()\n",
    "    \n",
    " \n",
    "    senders = single_graph.row.astype(jnp.int64)\n",
    "    receivers = single_graph.col.astype(jnp.int64)\n",
    "    values = single_graph.data.astype(jnp.int64)\n",
    "    n_node = jnp.asarray([single_graph.shape[0]])\n",
    " \n",
    "    values = np.array([0]) if values.size == 0 else values\n",
    "    n_edge = np.array([np.sum(values)])\n",
    "    senders = np.repeat(senders, values)\n",
    "    receivers = np.repeat(receivers, values)\n",
    "    \n",
    "    if len(senders) < max_n_edge:\n",
    "        senders = jnp.concatenate( [senders, -1*jnp.ones( max_n_edge - len(senders)  )] )\n",
    "        receivers = jnp.concatenate( [receivers, -1*jnp.ones(max_n_edge - len(receivers)   )] )\n",
    "        \n",
    "    \n",
    "     \n",
    "    senders_list.append( jnp.asarray(senders).astype(jnp.int32)  )\n",
    "    receivers_list.append( jnp.asarray(receivers).astype(jnp.int32) )\n",
    "    \n",
    "    n_node_list.append( jnp.asarray(n_node).astype(jnp.int32) )\n",
    "    n_edge_list.append( jnp.asarray(n_edge).astype(jnp.int32) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e5482243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(node_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "96f9da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_list_padded = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "280d4bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10292/10292 [00:04<00:00, 2366.66it/s]\n"
     ]
    }
   ],
   "source": [
    "#here padding the node features with np.inf\n",
    "for node_features in tqdm(node_features_list ):\n",
    "    if len(node_features) < max_n_node:\n",
    "        \n",
    "        node_features = jnp.concatenate( [node_features, 0*jnp.ones( (max_n_node-len(node_features), jnp.squeeze(node_features ).shape[-1])  )] )\n",
    "    node_features_list_padded.append( jnp.asarray(node_features).astype(jnp.float32)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecbda61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c75c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b238a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "senders_list = jnp.array(senders_list)\n",
    "receivers_list = jnp.array(receivers_list)\n",
    "\n",
    "n_node_list = jnp.array(n_node_list)\n",
    "n_edge_list = jnp.array(n_edge_list)\n",
    "\n",
    "node_features_list_padded = jnp.array(node_features_list_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a5fa82ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10292, 227, 2)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_list_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "22d79429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10292, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_edge_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7bad61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GP =  gn_graph.GraphsTuple(\n",
    "      nodes=node_features_list_padded,  \n",
    "      edges=-1*jnp.ones_like(n_node_list),\n",
    "      receivers= receivers_list   ,\n",
    "      senders= senders_list ,\n",
    "      globals=  -1*jnp.ones_like(n_node_list),\n",
    "      n_node=n_node_list,\n",
    "      n_edge=n_edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cfc49d1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "dset = tf.data.Dataset.from_tensor_slices(GP)\n",
    "\n",
    "dset = dset.repeat()\n",
    "dset = dset.shuffle(buffer_size=10000)\n",
    "dset = dset.batch(batch_size)\n",
    "dset = dset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "dset = dset.as_numpy_iterator()\n",
    "_ = next(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f4613b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = next(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cdbf1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dset2 = tf.data.Dataset.from_tensor_slices(GP)\n",
    "\n",
    "dset2 = dset2.repeat()\n",
    "dset2 = dset2.shuffle(buffer_size=10000)\n",
    "dset2 = dset2.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "dset2 = dset2.as_numpy_iterator()\n",
    "g_init = next(dset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f91564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dffbde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L506\n",
    "def GraphConvolution(update_node_fn: Callable,\n",
    "                     aggregate_nodes_fn: Callable = jax.ops.segment_sum,\n",
    "                     add_self_edges: bool = False,\n",
    "                     symmetric_normalization: bool = False) -> Callable:\n",
    "  \"\"\"Returns a method that applies a Graph Convolution layer.\n",
    "\n",
    "  Graph Convolutional layer as in https://arxiv.org/abs/1609.02907,\n",
    "  NOTE: This implementation does not add an activation after aggregation.\n",
    "  If you are stacking layers, you may want to add an activation between\n",
    "  each layer.\n",
    "  Args:\n",
    "    update_node_fn: function used to update the nodes. In the paper a single\n",
    "      layer MLP is used.\n",
    "    aggregate_nodes_fn: function used to aggregates the sender nodes.\n",
    "    add_self_edges: whether to add self edges to nodes in the graph as in the\n",
    "      paper definition of GCN. Defaults to False.\n",
    "    symmetric_normalization: whether to use symmetric normalization. Defaults to\n",
    "      True.\n",
    "\n",
    "  Returns:\n",
    "    A method that applies a Graph Convolution layer.\n",
    "  \"\"\"\n",
    "\n",
    "  def _ApplyGCN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "    \"\"\"Applies a Graph Convolution layer.\"\"\"\n",
    "    nodes, _, receivers, senders, _, _, _ = graph\n",
    "\n",
    "    # First pass nodes through the node updater.\n",
    "    nodes = update_node_fn(nodes)\n",
    "    # Equivalent to jnp.sum(n_node), but jittable\n",
    "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
    "    if add_self_edges:\n",
    "      # We add self edges to the senders and receivers so that each node\n",
    "      # includes itself in aggregation.\n",
    "      # In principle, a `GraphsTuple` should partition by n_edge, but in\n",
    "      # this case it is not required since a GCN is agnostic to whether\n",
    "      # the `GraphsTuple` is a batch of graphs or a single large graph.\n",
    "      conv_receivers, conv_senders = add_self_edges_fn(receivers, senders,\n",
    "                                                       total_num_nodes)\n",
    "    else:\n",
    "      conv_senders = senders\n",
    "      conv_receivers = receivers\n",
    "\n",
    "    # pylint: disable=g-long-lambda\n",
    "    if symmetric_normalization:\n",
    "      # Calculate the normalization values.\n",
    "      count_edges = lambda x: jax.ops.segment_sum(\n",
    "          jnp.ones_like(conv_senders), x, total_num_nodes)\n",
    "      sender_degree = count_edges(conv_senders)\n",
    "      receiver_degree = count_edges(conv_receivers)\n",
    "\n",
    "      # Pre normalize by sqrt sender degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: x * jax.lax.rsqrt(jnp.maximum(sender_degree, 1.0))[:, None],\n",
    "          nodes,\n",
    "      )\n",
    "      # Aggregate the pre-normalized nodes.\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "      # Post normalize by sqrt receiver degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x:\n",
    "          (x * jax.lax.rsqrt(jnp.maximum(receiver_degree, 1.0))[:, None]),\n",
    "          nodes,\n",
    "      )\n",
    "    else:\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "    # pylint: enable=g-long-lambda\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  return _ApplyGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "afca7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_update_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP([64,64,64], activation=jax.nn.leaky_relu)(feats)\n",
    "  \n",
    "  #Linear(2) #two features feature.shape\n",
    "  \n",
    "  return net\n",
    "\n",
    "\n",
    "def gcn_definition(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "  \"\"\"Defines a GCN for the karate club task.\n",
    "  Args:\n",
    "    graph: GraphsTuple the network processes.\n",
    "\n",
    "  Returns:\n",
    "    output graph with updated node values.\n",
    "  \"\"\"\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=node_update_fn,\n",
    "      add_self_edges=False)\n",
    "  graph = gn(graph)\n",
    "\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=hk.Linear(2)) # output dim is 2 because we have 2 scalars.\n",
    "  graph = gn(graph)\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85f80bce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network = hk.without_apply_rng(hk.transform(gcn_definition ))\n",
    "\n",
    "\n",
    "#params = jax.vmap(lambda x: network.init( next(rng) , x))  (g)\n",
    "\n",
    "params =  network.init( next(rng) , g_init )\n",
    "\n",
    "#out_graph = jax.vmap(lambda x,y: network.apply(x,y))   (params, g)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c6144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e4294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d89a2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def prediction_loss(params: hk.Params, graph_batch: jraph.GraphsTuple ) -> jnp.ndarray:\n",
    "    \n",
    "    predicted_graph = jax.vmap ( lambda x: network.apply(params, x)) (graph_batch)\n",
    "    \n",
    "    #MSE\n",
    "    loss =  jnp.linalg.norm(predicted_graph.nodes -  graph_batch.nodes, axis=-1) **2\n",
    "    \n",
    "    return jnp.mean(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e6d48a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update = optax.adam(1e-4)\n",
    "opt_state = opt_init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "69e1dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(params: hk.Params, opt_state, graph_batch: jraph.GraphsTuple) -> Tuple[hk.Params, Any]:\n",
    "    \n",
    "    loss, grads = jax.value_and_grad(prediction_loss)(params, graph_batch)\n",
    "\n",
    "    updates, opt_state = opt_update(grads, opt_state)\n",
    "    \n",
    "    return optax.apply_updates(params, updates), opt_state, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e3b231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "params_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4011be02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<16:29,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.053686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/1000 [00:01<10:47,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.98671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/1000 [00:01<08:56,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1986.2402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/1000 [00:02<08:04,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984.5687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/1000 [00:02<07:35,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103541.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 6/1000 [00:03<07:18,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.86092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 7/1000 [00:03<07:06,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.710014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 8/1000 [00:03<06:58,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4357.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 9/1000 [00:04<06:53,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550.7398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 10/1000 [00:04<06:50,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.631542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 11/1000 [00:05<06:47,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.91623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 12/1000 [00:05<06:45,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.375707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|         | 13/1000 [00:05<06:44,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.710489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|         | 14/1000 [00:06<06:43,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3303.7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 15/1000 [00:06<06:44,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8808155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 16/1000 [00:07<06:42,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.67332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 17/1000 [00:07<06:41,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13202.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 18/1000 [00:07<06:42,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.117339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 19/1000 [00:08<06:41,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.496574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 20/1000 [00:08<06:40,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5902452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 21/1000 [00:09<06:39,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8792659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 22/1000 [00:09<06:38,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433.06403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 23/1000 [00:09<06:38,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.80753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 24/1000 [00:10<06:37,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6124662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 25/1000 [00:10<06:37,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.22552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 26/1000 [00:11<06:36,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.901386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 27/1000 [00:11<06:36,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.67957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 28/1000 [00:11<06:35,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.971074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 29/1000 [00:12<06:36,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.172693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 30/1000 [00:12<06:35,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4575833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 31/1000 [00:13<06:34,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.56828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 32/1000 [00:13<06:35,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510.62354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 33/1000 [00:14<06:34,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6147361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 34/1000 [00:14<06:33,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.37936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 35/1000 [00:14<06:33,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3476324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 36/1000 [00:15<06:32,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4249289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 37/1000 [00:15<06:31,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9468362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 38/1000 [00:16<06:31,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4029734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 39/1000 [00:16<06:30,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3738477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 40/1000 [00:16<06:32,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7658086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 41/1000 [00:17<06:31,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8101892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 42/1000 [00:17<06:30,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5909469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 43/1000 [00:18<06:29,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5251161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 44/1000 [00:18<06:29,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.082191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 45/1000 [00:18<06:30,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3714764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 46/1000 [00:19<06:29,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.593192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 47/1000 [00:19<06:28,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.782849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 48/1000 [00:20<06:27,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6986215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 49/1000 [00:20<06:27,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.473446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 50/1000 [00:20<06:26,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3276474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 51/1000 [00:21<06:25,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 52/1000 [00:21<06:25,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7802689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 53/1000 [00:22<06:24,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.289768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|         | 54/1000 [00:22<06:24,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.211449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 55/1000 [00:22<06:24,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3904419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 56/1000 [00:23<06:23,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324.41794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 57/1000 [00:23<06:23,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2321823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 58/1000 [00:24<06:23,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7243676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 59/1000 [00:24<06:23,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.374466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 60/1000 [00:25<06:23,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3751705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 61/1000 [00:25<06:22,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.416296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 62/1000 [00:25<06:21,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6422586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 63/1000 [00:26<06:20,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488.11093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|         | 64/1000 [00:26<06:20,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.478011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 64/1000 [00:27<06:35,  2.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)):\n\u001b[0;32m----> 2\u001b[0m      params, opt_state, loss \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m      \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m      4\u001b[0m      losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m__new__\u001b[0;34m(_cls, count, mu, nu)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for step in tqdm(range(1000)):\n",
    "     params, opt_state, loss = update(params, opt_state, next(dset))\n",
    "     print(loss)\n",
    "     losses.append(loss)\n",
    "     params_list.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b507138f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14b6ad169340>]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10c96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    " @jax.jit\n",
    "  def update(params: hk.Params, opt_state) -> Tuple[hk.Params, Any]:\n",
    "    \"\"\"Returns updated params and state.\"\"\"\n",
    "    g = jax.grad(prediction_loss)(params)\n",
    "    updates, opt_state = opt_update(g, opt_state)\n",
    "    return optax.apply_updates(params, updates), opt_state\n",
    "\n",
    "  @jax.jit\n",
    "  def accuracy(params: hk.Params) -> jnp.ndarray:\n",
    "    decoded_graph = network.apply(params, zacharys_karate_club)\n",
    "    return jnp.mean(jnp.argmax(decoded_graph.nodes, axis=1) == labels)\n",
    "\n",
    "  for step in range(num_steps):\n",
    "    print(f\"step {step} accuracy {accuracy(params).item():.2f}\")\n",
    "    params, opt_state = update(params, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78fbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_club(network: hk.Transformed, num_steps: int, graph_batch: jraph.GraphsTuple) -> jnp.ndarray:\n",
    "  \"\"\"Solves the karate club problem by optimizing the assignments of students.\"\"\"\n",
    "  graph_batch = get_zacharys_karate_club()\n",
    "  labels = get_ground_truth_assignments_for_zacharys_karate_club()\n",
    "  params = network.init(jax.random.PRNGKey(42), zacharys_karate_club)\n",
    "\n",
    "  @jax.jit\n",
    "  def predict(params: hk.Params) -> jnp.ndarray:\n",
    "    predicted_graph = network.apply(params, graph_batch)\n",
    "    return predicted_graph\n",
    "\n",
    "  @jax.jit\n",
    "  def prediction_loss(params: hk.Params) -> jnp.ndarray:\n",
    "    decoded_graph = network.apply(params, graph_batch)\n",
    "    # We interpret the decoded nodes as a pair of logits for each node.\n",
    "    log_prob = jax.nn.log_softmax(decoded_graph.nodes)\n",
    "    # The only two assignments we know a-priori are those of Mr. Hi (Node 0)\n",
    "    # and John A (Node 33).\n",
    "    return -(log_prob[0, 0] + log_prob[33, 1])\n",
    "\n",
    "  opt_init, opt_update = optax.adam(1e-2)\n",
    "  opt_state = opt_init(params)\n",
    "\n",
    "  @jax.jit\n",
    "  def update(params: hk.Params, opt_state) -> Tuple[hk.Params, Any]:\n",
    "    \"\"\"Returns updated params and state.\"\"\"\n",
    "    g = jax.grad(prediction_loss)(params)\n",
    "    updates, opt_state = opt_update(g, opt_state)\n",
    "    return optax.apply_updates(params, updates), opt_state\n",
    "\n",
    "  @jax.jit\n",
    "  def accuracy(params: hk.Params) -> jnp.ndarray:\n",
    "    decoded_graph = network.apply(params, zacharys_karate_club)\n",
    "    return jnp.mean(jnp.argmax(decoded_graph.nodes, axis=1) == labels)\n",
    "\n",
    "  for step in range(num_steps):\n",
    "    print(f\"step {step} accuracy {accuracy(params).item():.2f}\")\n",
    "    params, opt_state = update(params, opt_state)\n",
    "\n",
    "  return predict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0252a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab6ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911af68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39801e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd4fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2143e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c248f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe60d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd9711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfd166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca68d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45d602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27412dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d999a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2aee7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c213cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592482e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jraph.concatenated_args\n",
    "def node_update_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.Sequential(\n",
    "      [hk.Linear(128), jax.nn.relu,\n",
    "       hk.Linear(128)])\n",
    "  return net(feats)\n",
    "\n",
    "\n",
    "def net_fn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "  # Add a global paramater for graph classification.\n",
    "  graph = graph._replace(globals=jnp.zeros([graph.n_node.shape[0], 1]))\n",
    "  embedder = jraph.GraphMapFeatures(\n",
    "      hk.Linear(128), hk.Linear(128), hk.Linear(128))\n",
    "  net = jraph.GraphNetwork(\n",
    "      update_node_fn=node_update_fn,\n",
    "      update_edge_fn=edge_update_fn,\n",
    "      update_global_fn=update_global_fn)\n",
    "  return net(embedder(graph)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d4f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(params: hk.Params, graph: jraph.GraphsTuple, label: jnp.ndarray,\n",
    "                 net: jraph.GraphsTuple) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "  \"\"\"Computes loss and accuracy.\"\"\"\n",
    "  pred_graph = net.apply(params, graph)\n",
    "  preds = jax.nn.log_softmax(pred_graph.globals)\n",
    "  targets = jax.nn.one_hot(label, 2)\n",
    "\n",
    "  # Since we have an extra 'dummy' graph in our batch due to padding, we want\n",
    "  # to mask out any loss associated with the dummy graph.\n",
    "  # Since we padded with `pad_with_graphs` we can recover the mask by using\n",
    "  # get_graph_padding_mask.\n",
    "  mask = jraph.get_graph_padding_mask(pred_graph)\n",
    "\n",
    "  # Cross entropy loss.\n",
    "  loss = -jnp.mean(preds * targets * mask[:, None])\n",
    "\n",
    "  # Accuracy taking into account the mask.\n",
    "  accuracy = jnp.sum(\n",
    "      (jnp.argmax(pred_graph.globals, axis=1) == label) * mask) / jnp.sum(mask)\n",
    "  return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/ogb_examples/train.py\n",
    "def train(dataset: List[Dict[str, Any]], num_train_steps: int) -> hk.Params:\n",
    "  \"\"\"Training loop.\"\"\"\n",
    "\n",
    "  # Transform impure `net_fn` to pure functions with hk.transform.\n",
    "  net = hk.without_apply_rng(hk.transform(net_fn))\n",
    "  # Get a candidate graph and label to initialize the network.\n",
    "  graph = dataset[0]['input_graph']\n",
    "\n",
    "  # Initialize the network.\n",
    "  params = net.init(jax.random.PRNGKey(42), graph)\n",
    "  # Initialize the optimizer.\n",
    "  opt_init, opt_update = optax.adam(1e-4)\n",
    "  opt_state = opt_init(params)\n",
    "\n",
    "  compute_loss_fn = functools.partial(compute_loss, net=net)\n",
    "  # We jit the computation of our loss, since this is the main computation.\n",
    "  # Using jax.jit means that we will use a single accelerator. If you want\n",
    "  # to use more than 1 accelerator, use jax.pmap. More information can be\n",
    "  # found in the jax documentation.\n",
    "  compute_loss_fn = jax.jit(jax.value_and_grad(\n",
    "      compute_loss_fn, has_aux=True))\n",
    "\n",
    "  for idx in range(num_train_steps):\n",
    "    graph = dataset[idx % len(dataset)]['input_graph']\n",
    "    label = dataset[idx % len(dataset)]['target']\n",
    "    # Jax will re-jit your graphnet every time a new graph shape is encountered.\n",
    "    # In the limit, this means a new compilation every training step, which\n",
    "    # will result in *extremely* slow training. To prevent this, pad each\n",
    "    # batch of graphs to the nearest power of two. Since jax maintains a cache\n",
    "    # of compiled programs, the compilation cost is amortized.\n",
    "    graph = pad_graph_to_nearest_power_of_two(graph)\n",
    "\n",
    "    # Since padding is implemented with pad_with_graphs, an extra graph has\n",
    "    # been added to the batch, which means there should be an extra label.\n",
    "    label = jnp.concatenate([label, jnp.array([0])])\n",
    "\n",
    "    (loss, acc), grad = compute_loss_fn(params, graph, label)\n",
    "    updates, opt_state = opt_update(grad, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    if idx % 50 == 0:\n",
    "      print(f'step: {idx}, loss: {loss}, acc: {acc}')\n",
    "  print('Training finished')\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = train(train_mutag_ds, num_train_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dfa6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c28355cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(hk.Module):\n",
    "  def __init__(self, features: jnp.ndarray):\n",
    "    super().__init__()\n",
    "    self.features = features\n",
    "\n",
    "  def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "    layers = []\n",
    "    for feat in self.features[:-1]:\n",
    "      layers.append(hk.Linear(feat))\n",
    "      layers.append(jax.nn.relu)\n",
    "    layers.append(hk.Linear(self.features[-1]))\n",
    "\n",
    "    mlp = hk.Sequential(layers)\n",
    "    return mlp(x)\n",
    "\n",
    "# Use MLP block to define the update node function\n",
    "update_node_fn = lambda x: MLP(features=[8, 4])(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18233c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L506\n",
    "def GraphConvolution(update_node_fn: Callable,\n",
    "                     aggregate_nodes_fn: Callable = jax.ops.segment_sum,\n",
    "                     add_self_edges: bool = False,\n",
    "                     symmetric_normalization: bool = False) -> Callable:\n",
    "  \"\"\"Returns a method that applies a Graph Convolution layer.\n",
    "\n",
    "  Graph Convolutional layer as in https://arxiv.org/abs/1609.02907,\n",
    "  NOTE: This implementation does not add an activation after aggregation.\n",
    "  If you are stacking layers, you may want to add an activation between\n",
    "  each layer.\n",
    "  Args:\n",
    "    update_node_fn: function used to update the nodes. In the paper a single\n",
    "      layer MLP is used.\n",
    "    aggregate_nodes_fn: function used to aggregates the sender nodes.\n",
    "    add_self_edges: whether to add self edges to nodes in the graph as in the\n",
    "      paper definition of GCN. Defaults to False.\n",
    "    symmetric_normalization: whether to use symmetric normalization. Defaults to\n",
    "      True.\n",
    "\n",
    "  Returns:\n",
    "    A method that applies a Graph Convolution layer.\n",
    "  \"\"\"\n",
    "\n",
    "  def _ApplyGCN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "    \"\"\"Applies a Graph Convolution layer.\"\"\"\n",
    "    nodes, _, receivers, senders, _, _, _ = graph\n",
    "\n",
    "    # First pass nodes through the node updater.\n",
    "    nodes = update_node_fn(nodes)\n",
    "    # Equivalent to jnp.sum(n_node), but jittable\n",
    "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
    "    if add_self_edges:\n",
    "      # We add self edges to the senders and receivers so that each node\n",
    "      # includes itself in aggregation.\n",
    "      # In principle, a `GraphsTuple` should partition by n_edge, but in\n",
    "      # this case it is not required since a GCN is agnostic to whether\n",
    "      # the `GraphsTuple` is a batch of graphs or a single large graph.\n",
    "      conv_receivers, conv_senders = add_self_edges_fn(receivers, senders,\n",
    "                                                       total_num_nodes)\n",
    "    else:\n",
    "      conv_senders = senders\n",
    "      conv_receivers = receivers\n",
    "\n",
    "    # pylint: disable=g-long-lambda\n",
    "    if symmetric_normalization:\n",
    "      # Calculate the normalization values.\n",
    "      count_edges = lambda x: jax.ops.segment_sum(\n",
    "          jnp.ones_like(conv_senders), x, total_num_nodes)\n",
    "      sender_degree = count_edges(conv_senders)\n",
    "      receiver_degree = count_edges(conv_receivers)\n",
    "\n",
    "      # Pre normalize by sqrt sender degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: x * jax.lax.rsqrt(jnp.maximum(sender_degree, 1.0))[:, None],\n",
    "          nodes,\n",
    "      )\n",
    "      # Aggregate the pre-normalized nodes.\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "      # Post normalize by sqrt receiver degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x:\n",
    "          (x * jax.lax.rsqrt(jnp.maximum(receiver_degree, 1.0))[:, None]),\n",
    "          nodes,\n",
    "      )\n",
    "    else:\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "    # pylint: enable=g-long-lambda\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  return _ApplyGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9bd7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "  \"\"\"Defines a graph neural network with 3 GCN layers.\n",
    "  Args:\n",
    "    graph: GraphsTuple the network processes.\n",
    "\n",
    "  Returns:\n",
    "    output graph with updated node values.\n",
    "  \"\"\"\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=lambda n: jax.nn.relu(hk.Linear(8)(n)),\n",
    "      add_self_edges=False)\n",
    "  graph = gn(graph)\n",
    "\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=lambda n: jax.nn.relu(hk.Linear(4)(n)),\n",
    "      add_self_edges=False)\n",
    "  graph = gn(graph)\n",
    "\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=hk.Linear(2))\n",
    "  graph = gn(graph)\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525be495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
