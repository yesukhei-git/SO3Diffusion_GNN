{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180eaf69-31e6-4aec-a341-0e4a3497f572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 14:22:57.613499: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import tensorflow_probability as tfp; tfp = tfp.substrates.jax\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "from jaxlie import SO3\n",
    "from so3dm.distributions.isotropic_gaussian import IsotropicGaussianSO3\n",
    "from so3dm.plotting import visualize_so3_probabilities, visualize_so3_density\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "from flax.metrics import tensorboard\n",
    "import haiku as hk\n",
    "import optax\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8071a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import radius_neighbors_graph\n",
    "import jraph\n",
    "from jraph import GraphConvolution\n",
    "from jraph._src import utils as jraph_utils\n",
    "from jraph._src import graph as gn_graph\n",
    "\n",
    "import networkx as nx\n",
    "import jax.tree_util as tree\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb694466-e71a-4d8f-aa2a-b10ca6462380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_force_compilation_parallelism=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99054b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75360/1757885639.py:5: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0594215-29ad-4b41-a9a0-ad0c4fabf896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.linalg.inv(jnp.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a121dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = hk.PRNGSequence(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6263e366-af61-41c1-988c-63edddf0aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from halotools_ia.correlation_functions import  ed_3d, ee_3d,gi_plus_3d, gi_plus_projected, ii_minus_3d, ii_minus_projected, ii_plus_3d, ii_plus_projected, ed_projected, ed_3d_one_two_halo_decomp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee030ed-0c33-4497-958c-23ecb05d73d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tng = pickle.load(  open('/jet/home/yjagvara/SO3Diffusion_Tidal/TNG100-1_99_non-reduced_galaxy_shapes_multi_scale_1024_MLP_only_cent.pkl', \"rb\" ) )\n",
    "tng = tng[tng['dm_mass']>0]\n",
    "tng = tng[log10(tng['dm_mass']*10**10)>9]\n",
    "tng = tng[log10(tng['mass']*10**10)>9]\n",
    "\n",
    "tng['mass'] = log10(tng['mass']*10**10)\n",
    "tng['mass'] = (tng['mass']  -jnp.mean(tng['mass']))/ jnp.std(tng['mass']) \n",
    "tng['dm_mass'] = log10(tng['dm_mass']*10**10)\n",
    "tng['dm_mass'] = (tng['dm_mass']  -jnp.mean(tng['dm_mass']))/ jnp.std(tng['dm_mass']) \n",
    "\n",
    "#tng = tng[tng['central_bool']==1.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aaedd1",
   "metadata": {},
   "source": [
    "## Process the data for SO(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9538258",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flat_mat_I = np.array( (tng['dm_av_x'], tng['dm_av_y'], tng['dm_av_z'], \n",
    "tng['dm_bv_x'], tng['dm_bv_y'], tng['dm_bv_z'],\n",
    "tng['dm_cv_x'], tng['dm_cv_y'], tng['dm_cv_z'])).T\n",
    "\n",
    "rot_mat_I = np.reshape(flat_mat_I, (len(flat_mat_I), 3, 3), order='F' )\n",
    "\n",
    "for i in range (len(rot_mat_I)):\n",
    "    if np.linalg.det(rot_mat_I[i] ) < 0:\n",
    "        rot_mat_I[i] = rot_mat_I[i] @ (np.eye(3)*-1)\n",
    "        \n",
    "flat_mat_T = np.array( (   tng['tid_av_x_0.5_1024'], tng['tid_av_y_0.5_1024'], tng['tid_av_z_0.5_1024'], \n",
    "tng['tid_bv_x_0.5_1024'], tng['tid_bv_y_0.5_1024'], tng['tid_bv_z_0.5_1024'],\n",
    "tng['tid_cv_x_0.5_1024'], tng['tid_cv_y_0.5_1024'], tng['tid_cv_z_0.5_1024']   )).T\n",
    "\n",
    "\n",
    "flat_scalar_T =  np.array((tng['tid_a_0.5_1024'],  tng['tid_b_0.5_1024'],  tng['tid_c_0.5_1024'])).T\n",
    "rot_mat_T = np.reshape(flat_mat_T, (len(flat_mat_T), 3, 3), order='F' )\n",
    "\n",
    "for i in range (len(rot_mat_T)):\n",
    "    if np.linalg.det(rot_mat_T[i] ) < 0:\n",
    "        rot_mat_T[i] = rot_mat_T[i] @ (np.eye(3)*-1)\n",
    "        \n",
    "\n",
    "pos_tng = np.array([tng['gal_pos_x'], tng['gal_pos_y'], tng['gal_pos_z']]).T\n",
    "quat_I = jax.vmap(lambda x: SO3.from_matrix(x).wxyz) (rot_mat_I)\n",
    "quat_T = jax.vmap(lambda x: SO3.from_matrix(x).wxyz) (rot_mat_T)\n",
    "ax_ang_T = jax.vmap(lambda x: SO3(x).log() ) (quat_T)\n",
    "data_dict = {'quat_I': quat_I, 'quat_T': quat_T, 'scalar_T': flat_scalar_T, 'a': jnp.array(tng['dm_a']), 'b': jnp.array(tng['dm_b']), 'c': jnp.array(tng['dm_c']) }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4523f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dist_std = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e296451",
   "metadata": {},
   "source": [
    "## Let's build the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a62847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_key='GroupID'\n",
    "pos_key=['gal_pos_x', 'gal_pos_y', 'gal_pos_z']\n",
    "scalar_key = ['mass', 'dm_mass']\n",
    "catalog = tng\n",
    "\n",
    " \n",
    "# It takes a minute but we precompute all the graphs and data\n",
    "# Identify the individual groups and pre-extract the relevant data\n",
    "\n",
    "group_ids = catalog[group_key].astype(jnp.int32)\n",
    "gids, idx = jnp.unique(group_ids, return_index=True) # gids are the unique group ids, in other words All the host halo IDS uniquely  extracted     idx = The indices of the first occurrences of the unique values in the original array. i.e index of the central galaxy\n",
    "Position = jnp.array(catalog[pos_key].to_pandas())\n",
    "Scalars = jnp.array(catalog[scalar_key].to_pandas())\n",
    "quat_I = jnp.array(quat_I)\n",
    "quat_T = jnp.array(quat_T)\n",
    "flat_scalar_T = jnp.array(flat_scalar_T)\n",
    "\n",
    "Scalars = jnp.concatenate([Scalars, flat_scalar_T], axis=-1)\n",
    "quat_I_T = jnp.concatenate([quat_I, quat_T], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77a7a795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17457, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5b37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scalar = 5 #number of scalar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de74b5ed-3dae-4a49-bbc6-c8f91b3e5485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10292/10292 [00:41<00:00, 245.43it/s]\n"
     ]
    }
   ],
   "source": [
    "graph_radius = 1 #Mpc/h\n",
    "graphs_list = []\n",
    "node_features_list = []\n",
    "positions_list = []\n",
    "direction_to_COM_list = []\n",
    "quat_list = []\n",
    "\n",
    "\n",
    "for gid in tqdm(gids):\n",
    "    \n",
    "    g = np.where(group_ids == gid)[0]\n",
    "    Positions_for_group = Position[g]\n",
    "    Features_for_group = Scalars[g]\n",
    "    quat_I_T_for_group = quat_I_T[g]\n",
    "\n",
    "    #keep only halos with more than 10 galaxies\n",
    "    if Features_for_group.shape[0] >10:\n",
    "\n",
    "        # Compute adjacency matrix for each entry\n",
    "        graph = radius_neighbors_graph(Positions_for_group, graph_radius, mode='connectivity',\n",
    "                                   include_self=False)\n",
    "\n",
    "        Positions_for_group_COM =  (Positions_for_group - Positions_for_group[0])\n",
    "        directions_to_COM = Positions_for_group_COM/jnp.linalg.norm(Positions_for_group_COM, axis=-1)[..., jnp.newaxis]\n",
    "\n",
    "\n",
    "        directions_to_COM = directions_to_COM.at[jnp.isnan(directions_to_COM)].set(0.0)\n",
    "\n",
    "        graphs_list.append(graph)\n",
    "        node_features_list.append(Features_for_group)\n",
    "\n",
    "        direction_to_COM_list.append(directions_to_COM)\n",
    "        positions_list.append(Positions_for_group_COM)\n",
    "        \n",
    "        quat_list.append(quat_I_T_for_group)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd627d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39f81f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_node = graphs_list[0].tocoo().shape[0]\n",
    "max_n_edge = graphs_list[0].tocoo().nnz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "babd3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "senders_list = []\n",
    "receivers_list = []\n",
    "n_node_list = []\n",
    "n_edge_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62db2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12261171",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:05<00:00, 23.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for single_graph in tqdm(graphs_list):\n",
    "    single_graph =  single_graph.tocoo()\n",
    "    \n",
    " \n",
    "    senders = single_graph.row.astype(jnp.int64)\n",
    "    receivers = single_graph.col.astype(jnp.int64)\n",
    "    values = single_graph.data.astype(jnp.int64)\n",
    "    n_node = jnp.asarray([single_graph.shape[0]])\n",
    " \n",
    "    values = np.array([0]) if values.size == 0 else values\n",
    "    n_edge = np.array([np.sum(values)])\n",
    "    senders = np.repeat(senders, values)\n",
    "    receivers = np.repeat(receivers, values)\n",
    "    \n",
    "    if len(senders) < max_n_edge:\n",
    "        senders = jnp.concatenate( [senders, -1*jnp.ones( max_n_edge - len(senders)  )] )\n",
    "        receivers = jnp.concatenate( [receivers, -1*jnp.ones(max_n_edge - len(receivers)   )] )\n",
    "        \n",
    "    \n",
    "     \n",
    "    senders_list.append( jnp.asarray(senders).astype(jnp.int32)  )\n",
    "    receivers_list.append( jnp.asarray(receivers).astype(jnp.int32) )\n",
    "    \n",
    "    n_node_list.append( jnp.asarray(n_node).astype(jnp.int32) )\n",
    "    n_edge_list.append( jnp.asarray(n_edge).astype(jnp.int32) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96f9da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_list_padded = []\n",
    "positions_list_padded = []\n",
    "direction_to_COM_list_padded = []\n",
    "quat_list_padded = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8e9f7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:01<00:00, 68.56it/s]\n"
     ]
    }
   ],
   "source": [
    "#here padding the node features with np.inf\n",
    "for quat in tqdm(quat_list ):\n",
    "    if len(quat) < max_n_node:\n",
    "        \n",
    "        quat = jnp.concatenate( [quat, 0*jnp.ones( (max_n_node-len(quat), jnp.squeeze(quat ).shape[-1])  )] )\n",
    "        \n",
    "    quat_list_padded.append( jnp.asarray(quat).astype(jnp.float32)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1958f135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:01<00:00, 67.82it/s]\n"
     ]
    }
   ],
   "source": [
    "#here padding the node features with np.inf\n",
    "for direction_to_COM in tqdm(direction_to_COM_list ):\n",
    "    if len(direction_to_COM) < max_n_node:\n",
    "        \n",
    "        direction_to_COM = jnp.concatenate( [direction_to_COM, 0*jnp.ones( (max_n_node-len(direction_to_COM), jnp.squeeze(direction_to_COM ).shape[-1])  )] )\n",
    "        \n",
    "    direction_to_COM_list_padded.append( jnp.asarray(direction_to_COM).astype(jnp.float32)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "280d4bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:01<00:00, 67.94it/s]\n"
     ]
    }
   ],
   "source": [
    "#here padding the node features with np.inf\n",
    "for node_features in tqdm(node_features_list ):\n",
    "    if len(node_features) < max_n_node:\n",
    "        \n",
    "        node_features = jnp.concatenate( [node_features, 0*jnp.ones( (max_n_node-len(node_features), jnp.squeeze(node_features ).shape[-1])  )] )\n",
    "        \n",
    "    node_features_list_padded.append( jnp.asarray(node_features).astype(jnp.float32)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ea28dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:00<00:00, 1362.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#here padding the node features with np.inf\n",
    "for positions in tqdm(positions_list ):\n",
    "    if len(positions) < max_n_node:\n",
    "        \n",
    "        positions = jnp.concatenate( [positions, 0*jnp.ones( (max_n_node-len(positions), jnp.squeeze(positions ).shape[-1])  )] )\n",
    "        \n",
    "    positions_list_padded.append( jnp.asarray(positions).astype(jnp.float32)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecbda61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c75c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b238a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "senders_list = jnp.array(senders_list)\n",
    "receivers_list = jnp.array(receivers_list)\n",
    "\n",
    "n_node_list = jnp.array(n_node_list)\n",
    "n_edge_list = jnp.array(n_edge_list)\n",
    "\n",
    "node_features_list_padded = jnp.array(node_features_list_padded)\n",
    "positions_list_padded = jnp.array(positions_list_padded)\n",
    "direction_to_COM_list_padded = jnp.array(direction_to_COM_list_padded)\n",
    "quat_list_padded = jnp.array(positions_list_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9dac1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_feats = jnp.concatenate([node_features_list_padded, quat_list_padded,  direction_to_COM_list_padded, positions_list_padded], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bad61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GP =  gn_graph.GraphsTuple(\n",
    "      nodes=concat_feats,  \n",
    "      edges=-1*jnp.ones_like(n_node_list),\n",
    "      receivers= receivers_list   ,\n",
    "      senders= senders_list ,\n",
    "      globals=  -1*jnp.ones_like(n_node_list),\n",
    "      n_node=n_node_list,\n",
    "      n_edge=n_edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfc49d1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dset = tf.data.Dataset.from_tensor_slices(GP)\n",
    "\n",
    "dset = dset.repeat()\n",
    "dset = dset.shuffle(buffer_size=10000)\n",
    "dset = dset.batch(batch_size)\n",
    "dset = dset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "dset = dset.as_numpy_iterator()\n",
    "_ = next(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4613b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = next(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de2d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5a01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdbf1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dset2 = tf.data.Dataset.from_tensor_slices(GP)\n",
    "\n",
    "dset2 = dset2.repeat()\n",
    "dset2 = dset2.shuffle(buffer_size=10000)\n",
    "dset2 = dset2.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "dset2 = dset2.as_numpy_iterator()\n",
    "g_init = next(dset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c058acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_e(feats: jnp.ndarray, in_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP([in_dim , in_dim ], activation=jax.nn.silu)(feats)\n",
    "  return net\n",
    "\n",
    "def f_inf(m_ij: jnp.ndarray, in_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP( [1,], activation=jax.nn.sigmoid)(m_ij)\n",
    "  return net\n",
    "\n",
    "def f_h(feats: jnp.ndarray, in_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP([in_dim,  ], activation=jax.nn.silu)(feats)\n",
    "  net = hk.Linear(in_dim)(net)\n",
    "  return net\n",
    "\n",
    "\n",
    "def f_x(feats: jnp.ndarray, in_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP([in_dim, in_dim  ], activation=jax.nn.silu)(feats)\n",
    "  net = hk.Linear(1)(net) \n",
    "  return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a86f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT modified\n",
    "def GNN(add_self_edges: bool = False ) -> Callable:\n",
    "  def _ApplyGNN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    " \n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    \n",
    "    \n",
    "    # Equivalent to the sum of n_node, but statically known.\n",
    "    try:\n",
    "      sum_n_node = nodes.shape[0]\n",
    "    except IndexError:\n",
    "      raise IndexError('GAT requires node features')\n",
    "\n",
    "    \n",
    "    \n",
    "    # position of the nodes are the last 3 entries in the features matrix\n",
    "    distances = jnp.linalg.norm( nodes[:,-3:][senders] - nodes[:,-3:][receivers], axis=-1)\n",
    "    node_feat = nodes[:,:n_scalar]\n",
    "    \n",
    "    input_dim = nodes[:,:n_scalar].shape[-1]\n",
    "    \n",
    "    \n",
    "    concat_feats = jnp.concatenate([ node_feat[senders], node_feat[receivers], distances.reshape((-1,1))**2 ], axis=-1)\n",
    "    m_ij = f_e(concat_feats, input_dim)\n",
    "    \n",
    "    \n",
    "    # predict edges\n",
    "    e_ij = f_inf(m_ij, input_dim)\n",
    "    \n",
    "    m_i = jraph_utils.segment_sum( e_ij*m_ij, receivers, num_segments=sum_n_node)\n",
    "\n",
    "    concat_for_hl1_i =  jnp.concatenate([node_feat,  m_i], axis=-1)\n",
    "    \n",
    "    \n",
    "    new_node_feat = node_feat + f_h(concat_for_hl1_i, input_dim) #h^(l+1)_i    f_h is the node update func\n",
    "\n",
    "     \n",
    "    position_mlp = f_x(concat_feats, input_dim)\n",
    "    prefac_xi_xj = (nodes[:,-3:][senders] - nodes[:,-3:][receivers])/ (distances.reshape((-1,1))+1)\n",
    "    \n",
    "    sum_xi_xj =  jraph_utils.segment_sum( prefac_xi_xj*position_mlp, receivers, num_segments=sum_n_node)\n",
    "    #sum_xi_xj = jnp.einsum('ij,ij ->i', prefac_xi_xj, position_mlp ) #f_x\n",
    "    \n",
    "    x_Lplus1_i = nodes[:,-3:] + sum_xi_xj\n",
    "      \n",
    "    \n",
    "    \n",
    "\n",
    "    x_Lplus1_i = x_Lplus1_i/jnp.linalg.norm(x_Lplus1_i, axis=-1 )[..., jnp.newaxis]\n",
    "    mask = jnp.isnan(x_Lplus1_i)  # boolean mask selecting non-nan values\n",
    "    x_Lplus1_i = jnp.where(~mask, x_Lplus1_i, 0)\n",
    "    \n",
    "    #x_Lplus1_i = jnp.nan_to_num(x_Lplus1_i, copy=False,nan=0.0, posinf=0.0, neginf=0.0)#    x_Lplus1_i.at[jnp.isnan(x_Lplus1_i)].set(0.0)\n",
    "    \n",
    "    \n",
    "    nodes = jnp.concatenate([new_node_feat, nodes[:,n_scalar:-3], x_Lplus1_i],axis=-1)\n",
    "    #print(nodes.shape)\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  # pylint: enable=g-long-lambda\n",
    "  return _ApplyGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0fb32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_expand_MLP(feats: jnp.ndarray, out_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP( [out_dim] )(feats)\n",
    "  return net\n",
    "\n",
    "\n",
    "def dim_expand(graph: jraph.GraphsTuple, out_dim) -> jraph.GraphsTuple:\n",
    "\n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    node_feat = nodes[:,:n_scalar]\n",
    "    new_node = dim_expand_MLP(node_feat, out_dim)\n",
    "    nodes = jnp.concatenate([new_node, nodes[:,n_scalar:]],axis=-1)\n",
    "    return graph._replace(nodes=nodes)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beabbea9",
   "metadata": {},
   "source": [
    "## The Noiser: takes in a batch ads noise and estimates the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b08ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def noiser(nodes_I, key, noise_dist_std=noise_dist_std):\n",
    "    key1, key2 =jax.random.split(key)\n",
    "    # Sample random noise from target noise distribution\n",
    "    s = noise_dist_std * jnp.abs(jax.random.normal(shape=[nodes_I.shape[0]], key=key1)) + 1e-3\n",
    "    @jax.vmap\n",
    "    def sample(quatX, scale,   seed ):\n",
    "        key3, key4 =jax.random.split(seed)\n",
    "        \n",
    "        dist_quat = IsotropicGaussianSO3(quatX, scale)\n",
    "        quatY = dist_quat.sample(seed=key3)\n",
    " \n",
    "        \n",
    "        def fn_quat(s_direction, val):\n",
    "            return dist_quat.log_prob( (SO3(val) @ SO3.exp(s_direction)).wxyz) \n",
    "        score_so3 = jax.grad(fn_quat)(jnp.zeros(3), quatY )   #direction of the derivative, can be chosen to be the identity\n",
    "        \n",
    "        return quatY, score_so3, scale.reshape([1])\n",
    "        #return { 'x_so3': quatX, 'y_so3': quatY, \n",
    "                 #'score_so3': score_so3, 's':scale.reshape([1]) }\n",
    "    \n",
    "    \n",
    "    # Generates training set batch\n",
    "  \n",
    "    return sample( nodes_I, s, jax.random.split(key2, nodes_I.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc5f07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MLP_so3(so3, feats, stdev, tensor_T):\n",
    "    so3_log = jax.vmap(lambda u: SO3(u).log())(so3)\n",
    "    net = jnp.concatenate([so3_log, feats, stdev, tensor_T],axis=-1)\n",
    "    net = hk.nets.MLP([256,256,256], activation=jax.nn.leaky_relu)(net)\n",
    "    net = hk.Linear( 3)(net)  \n",
    "    return net/stdev \n",
    "\n",
    "\n",
    "def so3_SGM_layer(graph: jraph.GraphsTuple, key) -> jraph.GraphsTuple:\n",
    "\n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    \n",
    "    nodes_scalar = nodes[:, :n_scalar]\n",
    "    nodes_so3 = nodes[:,n_scalar:-3]\n",
    "    nodes_I = nodes_so3[:,:4]\n",
    "    nodes_T = nodes_so3[:,4:]\n",
    "    \n",
    "    noised_I, noised_I_score, stdev = noiser(nodes_I, key, noise_dist_std=noise_dist_std)\n",
    "    \n",
    "    output_score = MLP_so3(noised_I, nodes_scalar, stdev, nodes_T)\n",
    "    return output_score, noised_I_score\n",
    "#     nodes = jnp.concatenate([new_node, nodes[:,n_scalar:]],axis=-1)\n",
    "    \n",
    "#     return graph._replace(nodes=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c0598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a569b2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced5484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1b868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afca7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "def gcn_definition(graph: jraph.GraphsTuple, key) -> jraph.GraphsTuple:\n",
    "  \"\"\"Defines a GCN for the karate club task.\n",
    "  Args:\n",
    "    graph: GraphsTuple the network processes.\n",
    "\n",
    "  Returns:\n",
    "    output graph with updated node values.\n",
    "  \"\"\"\n",
    "  graph = dim_expand(graph,   32)\n",
    "    \n",
    "  gn = GNN( \n",
    "      add_self_edges=False )\n",
    "  graph = gn(graph)\n",
    "  \n",
    "  \n",
    "\n",
    "  gn = GNN(add_self_edges=False) # output dim is 2 because we have 2 scalars.\n",
    "  graph = gn(graph)\n",
    "    \n",
    "  graph = dim_expand(graph,   32)\n",
    "  #key = next(rng)\n",
    "  output_score, true_score = so3_SGM_layer(graph, key )#only do node operations, no messages\n",
    "\n",
    "\n",
    "  return output_score, true_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80d70542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphsTuple(nodes=array([[ 2.9130838 ,  3.0667794 ,  7.3337674 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.1524162 ,  1.1580101 ,  6.9149356 , ..., -0.08234406,\n",
       "        -0.17825317, -0.22185516],\n",
       "       [ 0.87462974,  0.64877856,  4.3584447 , ..., -0.04729843,\n",
       "         0.22956848,  0.7696276 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32), edges=array([-1], dtype=int32), receivers=array([ 1,  2,  3, ..., -1, -1, -1], dtype=int32), senders=array([ 0,  0,  0, ..., -1, -1, -1], dtype=int32), globals=array([-1], dtype=int32), n_node=array([16], dtype=int32), n_edge=array([224], dtype=int32))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "85f80bce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid nan value encountered in the output of a C++-jit/pmap function. Calling the de-optimized version.\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "invalid value (nan) encountered in jit(div)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/api.py:131\u001b[0m, in \u001b[0;36m_nan_check_posthook\u001b[0;34m(fun, args, kwargs, output)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m   \u001b[38;5;66;03m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/dispatch.py:436\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 436\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in pjit",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py:1920\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1920\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/dispatch.py:436\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 436\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(true_divide)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/runpy.py:194\u001b[0m, in \u001b[0;36m_run_module_as_main\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    193\u001b[0m     sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m mod_spec\u001b[38;5;241m.\u001b[39morigin\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _run_code(code, main_globals, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    195\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m, mod_spec)\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/runpy.py:87\u001b[0m, in \u001b[0;36m_run_code\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     80\u001b[0m run_globals\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m mod_name,\n\u001b[1;32m     81\u001b[0m                    \u001b[38;5;18m__file__\u001b[39m \u001b[38;5;241m=\u001b[39m fname,\n\u001b[1;32m     82\u001b[0m                    __cached__ \u001b[38;5;241m=\u001b[39m cached,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m                    __package__ \u001b[38;5;241m=\u001b[39m pkg_name,\n\u001b[1;32m     86\u001b[0m                    __spec__ \u001b[38;5;241m=\u001b[39m mod_spec)\n\u001b[0;32m---> 87\u001b[0m exec(code, run_globals)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_globals\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel_launcher.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipykernel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kernelapp \u001b[38;5;28;01mas\u001b[39;00m app\n\u001b[0;32m---> 17\u001b[0m app\u001b[38;5;241m.\u001b[39mlaunch_new_instance()\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/traitlets/config/application.py:992\u001b[0m, in \u001b[0;36mApplication.launch_instance\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    991\u001b[0m app\u001b[38;5;241m.\u001b[39minitialize(argv)\n\u001b[0;32m--> 992\u001b[0m app\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/kernelapp.py:711\u001b[0m, in \u001b[0;36mIPKernelApp.start\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_loop\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/tornado/platform/asyncio.py:215\u001b[0m, in \u001b[0;36mBaseAsyncIOLoop.start\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    214\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mset_event_loop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masyncio_loop)\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masyncio_loop\u001b[38;5;241m.\u001b[39mrun_forever()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/asyncio/base_events.py:570\u001b[0m, in \u001b[0;36mBaseEventLoop.run_forever\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once()\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/asyncio/base_events.py:1859\u001b[0m, in \u001b[0;36mBaseEventLoop._run_once\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m         handle\u001b[38;5;241m.\u001b[39m_run()\n\u001b[1;32m   1860\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/asyncio/events.py:81\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/kernelbase.py:510\u001b[0m, in \u001b[0;36mKernel.dispatch_queue\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 510\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_one()\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/kernelbase.py:499\u001b[0m, in \u001b[0;36mKernel.process_one\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m dispatch(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/kernelbase.py:406\u001b[0m, in \u001b[0;36mKernel.dispatch_shell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/kernelbase.py:729\u001b[0m, in \u001b[0;36mKernel.execute_request\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(reply_content):\n\u001b[0;32m--> 729\u001b[0m     reply_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m reply_content\n\u001b[1;32m    731\u001b[0m \u001b[38;5;66;03m# Flush output before sending the reply.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/ipkernel.py:411\u001b[0m, in \u001b[0;36mIPythonKernel.do_execute\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_cell_id:\n\u001b[0;32m--> 411\u001b[0m     res \u001b[38;5;241m=\u001b[39m shell\u001b[38;5;241m.\u001b[39mrun_cell(\n\u001b[1;32m    412\u001b[0m         code,\n\u001b[1;32m    413\u001b[0m         store_history\u001b[38;5;241m=\u001b[39mstore_history,\n\u001b[1;32m    414\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[1;32m    415\u001b[0m         cell_id\u001b[38;5;241m=\u001b[39mcell_id,\n\u001b[1;32m    416\u001b[0m     )\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/zmqshell.py:531\u001b[0m, in \u001b[0;36mZMQInteractiveShell.run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_cell(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2961\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2960\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_cell(\n\u001b[1;32m   2962\u001b[0m         raw_cell, store_history, silent, shell_futures, cell_id\n\u001b[1;32m   2963\u001b[0m     )\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3016\u001b[0m, in \u001b[0;36mInteractiveShell._run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3015\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3016\u001b[0m     result \u001b[38;5;241m=\u001b[39m runner(coro)\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/async_helpers.py:129\u001b[0m, in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3221\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_async\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3218\u001b[0m interactivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mast_node_interactivity\n\u001b[0;32m-> 3221\u001b[0m has_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_ast_nodes(code_ast\u001b[38;5;241m.\u001b[39mbody, cell_name,\n\u001b[1;32m   3222\u001b[0m        interactivity\u001b[38;5;241m=\u001b[39minteractivity, compiler\u001b[38;5;241m=\u001b[39mcompiler, result\u001b[38;5;241m=\u001b[39mresult)\n\u001b[1;32m   3224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_execution_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m has_raised\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3400\u001b[0m, in \u001b[0;36mInteractiveShell.run_ast_nodes\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3399\u001b[0m     asy \u001b[38;5;241m=\u001b[39m compare(code)\n\u001b[0;32m-> 3400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_code(code, result, async_\u001b[38;5;241m=\u001b[39masy):\n\u001b[1;32m   3401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3460\u001b[0m, in \u001b[0;36mInteractiveShell.run_code\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3459\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3460\u001b[0m         exec(code_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_global_ns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[1;32m   3461\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3462\u001b[0m     \u001b[38;5;66;03m# Reset our crash handler in place\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m\n\u001b[1;32m     23\u001b[0m Positions_for_group_COM \u001b[38;5;241m=\u001b[39m  (Positions_for_group \u001b[38;5;241m-\u001b[39m Positions_for_group[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 24\u001b[0m directions_to_COM \u001b[38;5;241m=\u001b[39m Positions_for_group_COM\u001b[38;5;241m/\u001b[39mjnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(Positions_for_group_COM, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, jnp\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m     27\u001b[0m directions_to_COM \u001b[38;5;241m=\u001b[39m directions_to_COM\u001b[38;5;241m.\u001b[39mat[jnp\u001b[38;5;241m.\u001b[39misnan(directions_to_COM)]\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m0.0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/array_methods.py:251\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 251\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m binary_op(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _rejected_binop_types):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/ufuncs.py:255\u001b[0m, in \u001b[0;36mtrue_divide\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    254\u001b[0m x1, x2 \u001b[38;5;241m=\u001b[39m promote_args_inexact(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_divide\u001b[39m\u001b[38;5;124m\"\u001b[39m, x1, x2)\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mdiv(x1, x2)\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m: FloatingPointError: invalid value (nan) encountered in jit(div)\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m network \u001b[38;5;241m=\u001b[39m hk\u001b[38;5;241m.\u001b[39mwithout_apply_rng(hk\u001b[38;5;241m.\u001b[39mtransform(gcn_definition ))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#params = jax.vmap(lambda x: network.init( next(rng) , x))  (g)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m params \u001b[38;5;241m=\u001b[39m  \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/transform.py:114\u001b[0m, in \u001b[0;36mwithout_state.<locals>.init_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 114\u001b[0m   params, state \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf your transformed function uses `hk.\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mget,set}_state` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthen use `hk.transform_with_state`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/transform.py:338\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.init_fn\u001b[0;34m(rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m base\u001b[38;5;241m.\u001b[39mnew_context(rng\u001b[38;5;241m=\u001b[39mrng) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[1;32m    337\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 13\u001b[0m, in \u001b[0;36mgcn_definition\u001b[0;34m(graph, key)\u001b[0m\n\u001b[1;32m      9\u001b[0m graph \u001b[38;5;241m=\u001b[39m dim_expand(graph,   \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     11\u001b[0m gn \u001b[38;5;241m=\u001b[39m GNN( \n\u001b[1;32m     12\u001b[0m     add_self_edges\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m )\n\u001b[0;32m---> 13\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mgn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m gn \u001b[38;5;241m=\u001b[39m GNN(add_self_edges\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# output dim is 2 because we have 2 scalars.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m graph \u001b[38;5;241m=\u001b[39m gn(graph)\n",
      "Cell \u001b[0;32mIn[31], line 49\u001b[0m, in \u001b[0;36mGNN.<locals>._ApplyGNN\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#sum_xi_xj = jnp.einsum('ij,ij ->i', prefac_xi_xj, position_mlp ) #f_x\u001b[39;00m\n\u001b[1;32m     44\u001b[0m x_Lplus1_i \u001b[38;5;241m=\u001b[39m nodes[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:] \u001b[38;5;241m+\u001b[39m sum_xi_xj\n\u001b[0;32m---> 49\u001b[0m x_Lplus1_i \u001b[38;5;241m=\u001b[39m \u001b[43mx_Lplus1_i\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_Lplus1_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     50\u001b[0m mask \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39misnan(x_Lplus1_i)  \u001b[38;5;66;03m# boolean mask selecting non-nan values\u001b[39;00m\n\u001b[1;32m     51\u001b[0m x_Lplus1_i \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;241m~\u001b[39mmask, x_Lplus1_i, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/array_methods.py:251\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    249\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 251\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _rejected_binop_types):\n\u001b[1;32m    253\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported operand type(s) for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopchar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/api.py:137\u001b[0m, in \u001b[0;36m_nan_check_posthook\u001b[0;34m(fun, args, kwargs, output)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid nan value encountered in the output of a C++-jit/pmap \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction. Calling the de-optimized version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache_miss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 17 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39missubdtype(dtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (inf) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(div)"
     ]
    }
   ],
   "source": [
    "network = hk.without_apply_rng(hk.transform(gcn_definition ))\n",
    "\n",
    "\n",
    "#params = jax.vmap(lambda x: network.init( next(rng) , x))  (g)\n",
    "\n",
    "params =  network.init( next(rng) , g_init, next(rng))\n",
    "\n",
    "#out_graph = jax.vmap(lambda x,y: network.apply(x,y))   (params, g)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a6c6144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear': {'b': Array([nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'linear_1': {'b': Array([nan], dtype=float32),\n",
       "  'w': Array([[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]], dtype=float32)},\n",
       " 'linear_2': {'b': Array([nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'linear_3': {'b': Array([0.], dtype=float32),\n",
       "  'w': Array([[ 0.21955472],\n",
       "         [ 0.20609367],\n",
       "         [-0.09408663],\n",
       "         [-0.18978944],\n",
       "         [-0.26372573]], dtype=float32)},\n",
       " 'linear_4': {'b': Array([nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]], dtype=float32)},\n",
       " 'mlp/~/linear_0': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_1/~/linear_0': {'b': Array([nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_1/~/linear_1': {'b': Array([nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_10/~/linear_0': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_10/~/linear_1': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_10/~/linear_2': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_2/~/linear_0': {'b': Array([nan], dtype=float32),\n",
       "  'w': Array([[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]], dtype=float32)},\n",
       " 'mlp_3/~/linear_0': {'b': Array([nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_4/~/linear_0': {'b': Array([nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_4/~/linear_1': {'b': Array([nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_5/~/linear_0': {'b': Array([nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_5/~/linear_1': {'b': Array([nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_6/~/linear_0': {'b': Array([nan], dtype=float32),\n",
       "  'w': Array([[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]], dtype=float32)},\n",
       " 'mlp_7/~/linear_0': {'b': Array([nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan]], dtype=float32)},\n",
       " 'mlp_8/~/linear_0': {'b': Array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "  'w': Array([[ 0.48477846,  0.32523447, -0.52129817,  0.29984108, -0.29987818],\n",
       "         [ 0.35926965,  0.19029419, -0.01888146,  0.03167036, -0.23888476],\n",
       "         [ 0.26626176,  0.09613348, -0.46724054, -0.2355803 , -0.3065065 ],\n",
       "         [-0.44137263, -0.14941804, -0.01460314,  0.31978402,  0.1695185 ],\n",
       "         [ 0.0401994 ,  0.1576643 , -0.3242277 ,  0.08996499,  0.16279732],\n",
       "         [ 0.2750897 , -0.2605921 , -0.13776052, -0.31080297,  0.41799474],\n",
       "         [ 0.4905007 ,  0.51796925,  0.09617582,  0.15937877,  0.19665033],\n",
       "         [-0.45426515,  0.2681146 , -0.31901416,  0.14460026, -0.32698786],\n",
       "         [-0.29148218, -0.03491911,  0.33337858,  0.25070503, -0.2443121 ],\n",
       "         [-0.20150046,  0.17978436,  0.04216721, -0.27567673, -0.0359726 ],\n",
       "         [-0.35315868, -0.02888874, -0.11599467,  0.11019664,  0.06170351]],      dtype=float32)},\n",
       " 'mlp_8/~/linear_1': {'b': Array([0., 0., 0., 0., 0.], dtype=float32),\n",
       "  'w': Array([[ 0.73634994,  0.0094321 ,  0.81522626, -0.42464522,  0.04263404],\n",
       "         [ 0.8274087 , -0.3353279 ,  0.7715597 ,  0.10077044,  0.00182759],\n",
       "         [-0.6708103 ,  0.10113367, -0.08828007,  0.54974544, -0.18703745],\n",
       "         [-0.11873552,  0.08232799,  0.0984064 , -0.59019375,  0.74262834],\n",
       "         [-0.15909158, -0.05819639, -0.14644101,  0.71655995,  0.3289798 ]],      dtype=float32)},\n",
       " 'mlp_9/~/linear_0': {'b': Array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan], dtype=float32),\n",
       "  'w': Array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "          nan, nan, nan, nan, nan, nan]], dtype=float32)}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e4294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d89a2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def prediction_loss(params: hk.Params, graph_batch: jraph.GraphsTuple, key ) -> jnp.ndarray:\n",
    "    \n",
    "    predicted_graph = jax.vmap ( lambda x, y: network.apply(params, x, y)) (graph_batch, key)\n",
    "    score_pred = predicted_graph[0]\n",
    "    score_true = predicted_graph[1]\n",
    "    \n",
    "    loss =  jnp.linalg.norm(score_pred   -  score_true, axis=-1) **2\n",
    "    \n",
    "    return jnp.mean(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6d48a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update = optax.adam(1e-3)\n",
    "opt_state = opt_init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69e1dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(params: hk.Params, opt_state, graph_batch: jraph.GraphsTuple, key) -> Tuple[hk.Params, Any]:\n",
    "    \n",
    "    loss, grads = jax.value_and_grad(prediction_loss)(params, graph_batch, key)\n",
    "\n",
    "    updates, opt_state = opt_update(grads, opt_state)\n",
    "    \n",
    "    return optax.apply_updates(params, updates), opt_state, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e3b231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "params_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae6e75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import config \n",
    "config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4011be02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "invalid value (nan) encountered in jit(dot_general)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py:1920\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1920\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/dispatch.py:436\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 436\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(update)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py:1920\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1920\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/dispatch.py:436\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[0;32m--> 436\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(prediction_loss)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/runpy.py:194\u001b[0m, in \u001b[0;36m_run_module_as_main\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    193\u001b[0m     sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m mod_spec\u001b[38;5;241m.\u001b[39morigin\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _run_code(code, main_globals, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    195\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m, mod_spec)\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/runpy.py:87\u001b[0m, in \u001b[0;36m_run_code\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     80\u001b[0m run_globals\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m mod_name,\n\u001b[1;32m     81\u001b[0m                    \u001b[38;5;18m__file__\u001b[39m \u001b[38;5;241m=\u001b[39m fname,\n\u001b[1;32m     82\u001b[0m                    __cached__ \u001b[38;5;241m=\u001b[39m cached,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m                    __package__ \u001b[38;5;241m=\u001b[39m pkg_name,\n\u001b[1;32m     86\u001b[0m                    __spec__ \u001b[38;5;241m=\u001b[39m mod_spec)\n\u001b[0;32m---> 87\u001b[0m exec(code, run_globals)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_globals\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel_launcher.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipykernel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kernelapp \u001b[38;5;28;01mas\u001b[39;00m app\n\u001b[0;32m---> 17\u001b[0m app\u001b[38;5;241m.\u001b[39mlaunch_new_instance()\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/traitlets/config/application.py:992\u001b[0m, in \u001b[0;36mApplication.launch_instance\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    991\u001b[0m app\u001b[38;5;241m.\u001b[39minitialize(argv)\n\u001b[0;32m--> 992\u001b[0m app\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/kernelapp.py:711\u001b[0m, in \u001b[0;36mIPKernelApp.start\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_loop\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/tornado/platform/asyncio.py:215\u001b[0m, in \u001b[0;36mBaseAsyncIOLoop.start\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    214\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mset_event_loop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masyncio_loop)\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masyncio_loop\u001b[38;5;241m.\u001b[39mrun_forever()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/asyncio/base_events.py:570\u001b[0m, in \u001b[0;36mBaseEventLoop.run_forever\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once()\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/asyncio/base_events.py:1859\u001b[0m, in \u001b[0;36mBaseEventLoop._run_once\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m         handle\u001b[38;5;241m.\u001b[39m_run()\n\u001b[1;32m   1860\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/asyncio/events.py:81\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/kernelbase.py:510\u001b[0m, in \u001b[0;36mKernel.dispatch_queue\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 510\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_one()\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/kernelbase.py:499\u001b[0m, in \u001b[0;36mKernel.process_one\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m dispatch(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/kernelbase.py:406\u001b[0m, in \u001b[0;36mKernel.dispatch_shell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/kernelbase.py:729\u001b[0m, in \u001b[0;36mKernel.execute_request\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(reply_content):\n\u001b[0;32m--> 729\u001b[0m     reply_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m reply_content\n\u001b[1;32m    731\u001b[0m \u001b[38;5;66;03m# Flush output before sending the reply.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/ipkernel.py:411\u001b[0m, in \u001b[0;36mIPythonKernel.do_execute\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_cell_id:\n\u001b[0;32m--> 411\u001b[0m     res \u001b[38;5;241m=\u001b[39m shell\u001b[38;5;241m.\u001b[39mrun_cell(\n\u001b[1;32m    412\u001b[0m         code,\n\u001b[1;32m    413\u001b[0m         store_history\u001b[38;5;241m=\u001b[39mstore_history,\n\u001b[1;32m    414\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[1;32m    415\u001b[0m         cell_id\u001b[38;5;241m=\u001b[39mcell_id,\n\u001b[1;32m    416\u001b[0m     )\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/ipykernel/zmqshell.py:531\u001b[0m, in \u001b[0;36mZMQInteractiveShell.run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_cell(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2961\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2960\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_cell(\n\u001b[1;32m   2962\u001b[0m         raw_cell, store_history, silent, shell_futures, cell_id\n\u001b[1;32m   2963\u001b[0m     )\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3016\u001b[0m, in \u001b[0;36mInteractiveShell._run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3015\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3016\u001b[0m     result \u001b[38;5;241m=\u001b[39m runner(coro)\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/async_helpers.py:129\u001b[0m, in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3221\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_async\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3218\u001b[0m interactivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mast_node_interactivity\n\u001b[0;32m-> 3221\u001b[0m has_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_ast_nodes(code_ast\u001b[38;5;241m.\u001b[39mbody, cell_name,\n\u001b[1;32m   3222\u001b[0m        interactivity\u001b[38;5;241m=\u001b[39minteractivity, compiler\u001b[38;5;241m=\u001b[39mcompiler, result\u001b[38;5;241m=\u001b[39mresult)\n\u001b[1;32m   3224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_execution_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m has_raised\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3400\u001b[0m, in \u001b[0;36mInteractiveShell.run_ast_nodes\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3399\u001b[0m     asy \u001b[38;5;241m=\u001b[39m compare(code)\n\u001b[0;32m-> 3400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_code(code, result, async_\u001b[38;5;241m=\u001b[39masy):\n\u001b[1;32m   3401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3460\u001b[0m, in \u001b[0;36mInteractiveShell.run_code\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3459\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3460\u001b[0m         exec(code_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_global_ns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[1;32m   3461\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3462\u001b[0m     \u001b[38;5;66;03m# Reset our crash handler in place\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#params = jax.vmap(lambda x: network.init( next(rng) , x))  (g)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m params \u001b[38;5;241m=\u001b[39m  network\u001b[38;5;241m.\u001b[39minit( \u001b[38;5;28mnext\u001b[39m(rng) , g_init, \u001b[38;5;28mnext\u001b[39m(rng))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/transform.py:114\u001b[0m, in \u001b[0;36mwithout_state.<locals>.init_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 114\u001b[0m   params, state \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39minit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    115\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m state:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/transform.py:338\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.init_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m   f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[35], line 9\u001b[0m, in \u001b[0;36mgcn_definition\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Defines a GCN for the karate club task.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m  graph: GraphsTuple the network processes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m  output graph with updated node values.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m graph \u001b[38;5;241m=\u001b[39m dim_expand(graph,   \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     11\u001b[0m gn \u001b[38;5;241m=\u001b[39m GNN( \n\u001b[1;32m     12\u001b[0m     add_self_edges\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m )\n",
      "Cell \u001b[0;32mIn[32], line 11\u001b[0m, in \u001b[0;36mdim_expand\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     10\u001b[0m node_feat \u001b[38;5;241m=\u001b[39m nodes[:,:n_scalar]\n\u001b[0;32m---> 11\u001b[0m new_node \u001b[38;5;241m=\u001b[39m dim_expand_MLP(node_feat, out_dim)\n\u001b[1;32m     12\u001b[0m nodes \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mconcatenate([new_node, nodes[:,n_scalar:]],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m, in \u001b[0;36mdim_expand_MLP\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Node update function for graph net.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m net \u001b[38;5;241m=\u001b[39m hk\u001b[38;5;241m.\u001b[39mnets\u001b[38;5;241m.\u001b[39mMLP( [out_dim] )(feats)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py:426\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    424\u001b[0m     f \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnamed_call(f, name\u001b[38;5;241m=\u001b[39mmethod_name)\n\u001b[0;32m--> 426\u001b[0m out \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py:272\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 272\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m bound_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    274\u001b[0m ctx \u001b[38;5;241m=\u001b[39m MethodContext(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m                     method_name\u001b[38;5;241m=\u001b[39mmethod_name,\n\u001b[1;32m    276\u001b[0m                     orig_method\u001b[38;5;241m=\u001b[39mbound_method)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/nets/mlp.py:113\u001b[0m, in \u001b[0;36mMLP.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m--> 113\u001b[0m   out \u001b[38;5;241m=\u001b[39m layer(out)\n\u001b[1;32m    114\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m (num_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate_final:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Only perform dropout if we are activating the output.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py:426\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    424\u001b[0m     f \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnamed_call(f, name\u001b[38;5;241m=\u001b[39mmethod_name)\n\u001b[0;32m--> 426\u001b[0m out \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py:272\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 272\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m bound_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    274\u001b[0m ctx \u001b[38;5;241m=\u001b[39m MethodContext(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m                     method_name\u001b[38;5;241m=\u001b[39mmethod_name,\n\u001b[1;32m    276\u001b[0m                     orig_method\u001b[38;5;241m=\u001b[39mbound_method)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/basic.py:178\u001b[0m, in \u001b[0;36mLinear.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    176\u001b[0m w \u001b[38;5;241m=\u001b[39m hk\u001b[38;5;241m.\u001b[39mget_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, [input_size, output_size], dtype, init\u001b[38;5;241m=\u001b[39mw_init)\n\u001b[0;32m--> 178\u001b[0m out \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mdot(inputs, w, precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_bias:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:2929\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _max(a_ndim, b_ndim) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 2929\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mdot(a, b, precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[1;32m   2931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m b_ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m: FloatingPointError: invalid value (nan) encountered in jit(dot_general)\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10_000\u001b[39m)):\n\u001b[0;32m----> 2\u001b[0m     params, opt_state, loss \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39misnan(loss):\n",
      "    \u001b[0;31m[... skipping hidden 23 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39missubdtype(dtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (inf) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(dot_general)"
     ]
    }
   ],
   "source": [
    "for step in tqdm(range(10_000)):\n",
    "    params, opt_state, loss = update(params, opt_state, next(dset), jax.random.split(next(rng), 64 )  )\n",
    "\n",
    "    print(loss)\n",
    "    if jnp.isnan(loss):\n",
    "        break\n",
    "    \n",
    "    if step%10==0 or step==0:\n",
    "        pickle.dump( params_list, open( \"/ocean/projects/phy210062p/yjagvara/EGNN_so3_weights.p\", \"wb\" ) )\n",
    "        pickle.dump( losses, open( \"/ocean/projects/phy210062p/yjagvara/EGNN_so3_losses.p\", \"wb\" ) )\n",
    "        losses.append(loss)\n",
    "        params_list.append(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c5ad5",
   "metadata": {},
   "source": [
    "losses = pickle.load(open( \"/ocean/projects/phy210062p/yjagvara/EGNN_losses.p\", \"rb\" ))\n",
    "params_list = pickle.load(open( \"/ocean/projects/phy210062p/yjagvara/EGNN_weights.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b507138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10c96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0252a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_graph = jax.vmap ( lambda x: network.apply(params_list[-1], x)) (GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "GP.nodes[:,:,n_scalar:n_scalar+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39801e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = jnp.einsum('...k,...k->...' ,  predicted_graph.nodes, GP.nodes[:,:,n_scalar:n_scalar+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b700c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_new = np.ma.masked_equal(t,0)\n",
    "print(t_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd4fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=hist(t_new[:20],bins=10,density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2143e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=hist(t_new[5],bins=20,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c248f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe60d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd9711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfd166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca68d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45d602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27412dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d999a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2aee7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c213cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592482e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jraph.concatenated_args\n",
    "def node_update_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.Sequential(\n",
    "      [hk.Linear(128), jax.nn.relu,\n",
    "       hk.Linear(128)])\n",
    "  return net(feats)\n",
    "\n",
    "\n",
    "def net_fn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "  # Add a global paramater for graph classification.\n",
    "  graph = graph._replace(globals=jnp.zeros([graph.n_node.shape[0], 1]))\n",
    "  embedder = jraph.GraphMapFeatures(\n",
    "      hk.Linear(128), hk.Linear(128), hk.Linear(128))\n",
    "  net = jraph.GraphNetwork(\n",
    "      update_node_fn=node_update_fn,\n",
    "      update_edge_fn=edge_update_fn,\n",
    "      update_global_fn=update_global_fn)\n",
    "  return net(embedder(graph)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d4f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(params: hk.Params, graph: jraph.GraphsTuple, label: jnp.ndarray,\n",
    "                 net: jraph.GraphsTuple) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "  \"\"\"Computes loss and accuracy.\"\"\"\n",
    "  pred_graph = net.apply(params, graph)\n",
    "  preds = jax.nn.log_softmax(pred_graph.globals)\n",
    "  targets = jax.nn.one_hot(label, 2)\n",
    "\n",
    "  # Since we have an extra 'dummy' graph in our batch due to padding, we want\n",
    "  # to mask out any loss associated with the dummy graph.\n",
    "  # Since we padded with `pad_with_graphs` we can recover the mask by using\n",
    "  # get_graph_padding_mask.\n",
    "  mask = jraph.get_graph_padding_mask(pred_graph)\n",
    "\n",
    "  # Cross entropy loss.\n",
    "  loss = -jnp.mean(preds * targets * mask[:, None])\n",
    "\n",
    "  # Accuracy taking into account the mask.\n",
    "  accuracy = jnp.sum(\n",
    "      (jnp.argmax(pred_graph.globals, axis=1) == label) * mask) / jnp.sum(mask)\n",
    "  return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/ogb_examples/train.py\n",
    "def train(dataset: List[Dict[str, Any]], num_train_steps: int) -> hk.Params:\n",
    "  \"\"\"Training loop.\"\"\"\n",
    "\n",
    "  # Transform impure `net_fn` to pure functions with hk.transform.\n",
    "  net = hk.without_apply_rng(hk.transform(net_fn))\n",
    "  # Get a candidate graph and label to initialize the network.\n",
    "  graph = dataset[0]['input_graph']\n",
    "\n",
    "  # Initialize the network.\n",
    "  params = net.init(jax.random.PRNGKey(42), graph)\n",
    "  # Initialize the optimizer.\n",
    "  opt_init, opt_update = optax.adam(1e-4)\n",
    "  opt_state = opt_init(params)\n",
    "\n",
    "  compute_loss_fn = functools.partial(compute_loss, net=net)\n",
    "  # We jit the computation of our loss, since this is the main computation.\n",
    "  # Using jax.jit means that we will use a single accelerator. If you want\n",
    "  # to use more than 1 accelerator, use jax.pmap. More information can be\n",
    "  # found in the jax documentation.\n",
    "  compute_loss_fn = jax.jit(jax.value_and_grad(\n",
    "      compute_loss_fn, has_aux=True))\n",
    "\n",
    "  for idx in range(num_train_steps):\n",
    "    graph = dataset[idx % len(dataset)]['input_graph']\n",
    "    label = dataset[idx % len(dataset)]['target']\n",
    "    # Jax will re-jit your graphnet every time a new graph shape is encountered.\n",
    "    # In the limit, this means a new compilation every training step, which\n",
    "    # will result in *extremely* slow training. To prevent this, pad each\n",
    "    # batch of graphs to the nearest power of two. Since jax maintains a cache\n",
    "    # of compiled programs, the compilation cost is amortized.\n",
    "    graph = pad_graph_to_nearest_power_of_two(graph)\n",
    "\n",
    "    # Since padding is implemented with pad_with_graphs, an extra graph has\n",
    "    # been added to the batch, which means there should be an extra label.\n",
    "    label = jnp.concatenate([label, jnp.array([0])])\n",
    "\n",
    "    (loss, acc), grad = compute_loss_fn(params, graph, label)\n",
    "    updates, opt_state = opt_update(grad, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    if idx % 50 == 0:\n",
    "      print(f'step: {idx}, loss: {loss}, acc: {acc}')\n",
    "  print('Training finished')\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = train(train_mutag_ds, num_train_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dfa6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28355cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(hk.Module):\n",
    "  def __init__(self, features: jnp.ndarray):\n",
    "    super().__init__()\n",
    "    self.features = features\n",
    "\n",
    "  def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "    layers = []\n",
    "    for feat in self.features[:-1]:\n",
    "      layers.append(hk.Linear(feat))\n",
    "      layers.append(jax.nn.relu)\n",
    "    layers.append(hk.Linear(self.features[-1]))\n",
    "\n",
    "    mlp = hk.Sequential(layers)\n",
    "    return mlp(x)\n",
    "\n",
    "# Use MLP block to define the update node function\n",
    "update_node_fn = lambda x: MLP(features=[8, 4])(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18233c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L506\n",
    "def GraphConvolution(update_node_fn: Callable,\n",
    "                     aggregate_nodes_fn: Callable = jax.ops.segment_sum,\n",
    "                     add_self_edges: bool = False,\n",
    "                     symmetric_normalization: bool = False) -> Callable:\n",
    "  \"\"\"Returns a method that applies a Graph Convolution layer.\n",
    "\n",
    "  Graph Convolutional layer as in https://arxiv.org/abs/1609.02907,\n",
    "  NOTE: This implementation does not add an activation after aggregation.\n",
    "  If you are stacking layers, you may want to add an activation between\n",
    "  each layer.\n",
    "  Args:\n",
    "    update_node_fn: function used to update the nodes. In the paper a single\n",
    "      layer MLP is used.\n",
    "    aggregate_nodes_fn: function used to aggregates the sender nodes.\n",
    "    add_self_edges: whether to add self edges to nodes in the graph as in the\n",
    "      paper definition of GCN. Defaults to False.\n",
    "    symmetric_normalization: whether to use symmetric normalization. Defaults to\n",
    "      True.\n",
    "\n",
    "  Returns:\n",
    "    A method that applies a Graph Convolution layer.\n",
    "  \"\"\"\n",
    "\n",
    "  def _ApplyGCN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "    \"\"\"Applies a Graph Convolution layer.\"\"\"\n",
    "    nodes, _, receivers, senders, _, _, _ = graph\n",
    "\n",
    "    # First pass nodes through the node updater.\n",
    "    nodes = update_node_fn(nodes)\n",
    "    # Equivalent to jnp.sum(n_node), but jittable\n",
    "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
    "    if add_self_edges:\n",
    "      # We add self edges to the senders and receivers so that each node\n",
    "      # includes itself in aggregation.\n",
    "      # In principle, a `GraphsTuple` should partition by n_edge, but in\n",
    "      # this case it is not required since a GCN is agnostic to whether\n",
    "      # the `GraphsTuple` is a batch of graphs or a single large graph.\n",
    "      conv_receivers, conv_senders = add_self_edges_fn(receivers, senders,\n",
    "                                                       total_num_nodes)\n",
    "    else:\n",
    "      conv_senders = senders\n",
    "      conv_receivers = receivers\n",
    "\n",
    "    # pylint: disable=g-long-lambda\n",
    "    if symmetric_normalization:\n",
    "      # Calculate the normalization values.\n",
    "      count_edges = lambda x: jax.ops.segment_sum(\n",
    "          jnp.ones_like(conv_senders), x, total_num_nodes)\n",
    "      sender_degree = count_edges(conv_senders)\n",
    "      receiver_degree = count_edges(conv_receivers)\n",
    "\n",
    "      # Pre normalize by sqrt sender degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: x * jax.lax.rsqrt(jnp.maximum(sender_degree, 1.0))[:, None],\n",
    "          nodes,\n",
    "      )\n",
    "      # Aggregate the pre-normalized nodes.\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "      # Post normalize by sqrt receiver degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x:\n",
    "          (x * jax.lax.rsqrt(jnp.maximum(receiver_degree, 1.0))[:, None]),\n",
    "          nodes,\n",
    "      )\n",
    "    else:\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "    # pylint: enable=g-long-lambda\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  return _ApplyGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "  \"\"\"Defines a graph neural network with 3 GCN layers.\n",
    "  Args:\n",
    "    graph: GraphsTuple the network processes.\n",
    "\n",
    "  Returns:\n",
    "    output graph with updated node values.\n",
    "  \"\"\"\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=lambda n: jax.nn.relu(hk.Linear(8)(n)),\n",
    "      add_self_edges=False)\n",
    "  graph = gn(graph)\n",
    "\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=lambda n: jax.nn.relu(hk.Linear(4)(n)),\n",
    "      add_self_edges=False)\n",
    "  graph = gn(graph)\n",
    "\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=hk.Linear(2))\n",
    "  graph = gn(graph)\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525be495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21324b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L506\n",
    "def GraphConvolution(update_node_fn: Callable,\n",
    "                     aggregate_nodes_fn: Callable = jax.ops.segment_sum,\n",
    "                     add_self_edges: bool = False,\n",
    "                     symmetric_normalization: bool = False) -> Callable:\n",
    "  \"\"\"Returns a method that applies a Graph Convolution layer.\n",
    "\n",
    "  Graph Convolutional layer as in https://arxiv.org/abs/1609.02907,\n",
    "  NOTE: This implementation does not add an activation after aggregation.\n",
    "  If you are stacking layers, you may want to add an activation between\n",
    "  each layer.\n",
    "  Args:\n",
    "    update_node_fn: function used to update the nodes. In the paper a single\n",
    "      layer MLP is used.\n",
    "    aggregate_nodes_fn: function used to aggregates the sender nodes.\n",
    "    add_self_edges: whether to add self edges to nodes in the graph as in the\n",
    "      paper definition of GCN. Defaults to False.\n",
    "    symmetric_normalization: whether to use symmetric normalization. Defaults to\n",
    "      True.\n",
    "\n",
    "  Returns:\n",
    "    A method that applies a Graph Convolution layer.\n",
    "  \"\"\"\n",
    "\n",
    "  def _ApplyGCN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "    \"\"\"Applies a Graph Convolution layer.\"\"\"\n",
    "    nodes, _, receivers, senders, _, _, _ = graph\n",
    "\n",
    "    # First pass nodes through the node updater.\n",
    "    nodes = update_node_fn(nodes)\n",
    "    # Equivalent to jnp.sum(n_node), but jittable\n",
    "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
    "    if add_self_edges:\n",
    "      # We add self edges to the senders and receivers so that each node\n",
    "      # includes itself in aggregation.\n",
    "      # In principle, a `GraphsTuple` should partition by n_edge, but in\n",
    "      # this case it is not required since a GCN is agnostic to whether\n",
    "      # the `GraphsTuple` is a batch of graphs or a single large graph.\n",
    "      conv_receivers, conv_senders = add_self_edges_fn(receivers, senders,\n",
    "                                                       total_num_nodes)\n",
    "    else:\n",
    "      conv_senders = senders\n",
    "      conv_receivers = receivers\n",
    "\n",
    "    # pylint: disable=g-long-lambda\n",
    "    if symmetric_normalization:\n",
    "      # Calculate the normalization values.\n",
    "      count_edges = lambda x: jax.ops.segment_sum(\n",
    "          jnp.ones_like(conv_senders), x, total_num_nodes)\n",
    "      sender_degree = count_edges(conv_senders)\n",
    "      receiver_degree = count_edges(conv_receivers)\n",
    "\n",
    "      # Pre normalize by sqrt sender degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: x * jax.lax.rsqrt(jnp.maximum(sender_degree, 1.0))[:, None],\n",
    "          nodes,\n",
    "      )\n",
    "      # Aggregate the pre-normalized nodes.\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "      # Post normalize by sqrt receiver degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x:\n",
    "          (x * jax.lax.rsqrt(jnp.maximum(receiver_degree, 1.0))[:, None]),\n",
    "          nodes,\n",
    "      )\n",
    "    else:\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "    # pylint: enable=g-long-lambda\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  return _ApplyGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044347fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT modified\n",
    "def GNN(add_self_edges: bool = False ) -> Callable:\n",
    " \n",
    " \n",
    "\n",
    "  def _ApplyGNN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    " \n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    \n",
    "    \n",
    "    #Equivalent to the sum of n_node, but statically known.\n",
    "    try:\n",
    "      sum_n_node = nodes.shape[0]\n",
    "    except IndexError:\n",
    "      raise IndexError('GAT requires node features')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # position of the nodes are the last 3 entries in the features matrix\n",
    "    \n",
    "    distances = jnp.linalg.norm( nodes[:,:3][senders] - nodes[:,:3][receivers], axis=-1)\n",
    "    node_feat = nodes[:,3:]\n",
    "    \n",
    "    input_dim = nodes[:,3:].shape[-1]\n",
    "    \n",
    "    \n",
    "    concat_feats = jnp.concatenate([ node_feat[senders], node_feat[receivers], distances.reshape((-1,1))**2 ], axis=-1)\n",
    "    m_ij = f_e(concat_feats, input_dim)\n",
    "    \n",
    "    \n",
    "    # predict edges\n",
    "    e_ij = f_inf(m_ij, input_dim)\n",
    "    \n",
    "    m_i = jraph_utils.segment_sum( e_ij*m_ij, receivers, num_segments=sum_n_node)\n",
    "\n",
    "    concat_for_hl1_i =  jnp.concatenate([node_feat,  m_i], axis=-1)\n",
    "    \n",
    "    \n",
    "    new_node_feat = node_feat + f_h(concat_for_hl1_i, input_dim) #h^(l+1)_i    f_h is the node update func\n",
    "\n",
    "     \n",
    "    position_mlp = f_x(concat_feats, input_dim)\n",
    "    prefac_xi_xj = (nodes[:,:3][senders] - nodes[:,:3][receivers])/ (distances.reshape((-1,1))+1)\n",
    "    \n",
    "    sum_xi_xj =  jraph_utils.segment_sum( prefac_xi_xj*position_mlp, receivers, num_segments=sum_n_node)\n",
    "    #sum_xi_xj = jnp.einsum('ij,ij ->i', prefac_xi_xj, position_mlp ) #f_x\n",
    "    \n",
    "    x_Lplus1_i = nodes[:,:3] + sum_xi_xj\n",
    "    \n",
    "    nodes = jnp.concatenate([x_Lplus1_i, new_node_feat],axis=-1)\n",
    "    #print(nodes.shape)\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  # pylint: enable=g-long-lambda\n",
    "  return _ApplyGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ed5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_expand_MLP(feats: jnp.ndarray, out_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.Linear( out_dim )(feats)\n",
    "  return net\n",
    "\n",
    "\n",
    "def dim_expand(graph: jraph.GraphsTuple, out_dim) -> jraph.GraphsTuple:\n",
    "\n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "\n",
    "    node_feat = nodes[:,3:]\n",
    "    in_dim = nodes[:,3:].shape[-1]\n",
    "    new_node = dim_expand_MLP(node_feat, out_dim)\n",
    "    \n",
    "    nodes = jnp.concatenate([nodes[:,:3], new_node],axis=-1)\n",
    "\n",
    "     \n",
    "    return graph._replace(nodes=nodes)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe45fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
