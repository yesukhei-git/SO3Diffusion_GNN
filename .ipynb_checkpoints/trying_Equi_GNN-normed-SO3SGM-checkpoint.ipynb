{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180eaf69-31e6-4aec-a341-0e4a3497f572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 17:08:36.149655: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/opt/packages/AI/tensorflow_23.02-2.10.0-py3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import tensorflow_probability as tfp; tfp = tfp.substrates.jax\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "from jaxlie import SO3\n",
    "from so3dm.distributions.isotropic_gaussian import IsotropicGaussianSO3\n",
    "from so3dm.plotting import visualize_so3_probabilities, visualize_so3_density\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "from flax.metrics import tensorboard\n",
    "import haiku as hk\n",
    "import optax\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8071a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import radius_neighbors_graph\n",
    "import jraph\n",
    "from jraph import GraphConvolution\n",
    "from jraph._src import utils as jraph_utils\n",
    "from jraph._src import graph as gn_graph\n",
    "\n",
    "import networkx as nx\n",
    "import jax.tree_util as tree\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb694466-e71a-4d8f-aa2a-b10ca6462380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_force_compilation_parallelism=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99054b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9980/1757885639.py:5: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0594215-29ad-4b41-a9a0-ad0c4fabf896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.linalg.inv(jnp.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a121dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = hk.PRNGSequence(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6263e366-af61-41c1-988c-63edddf0aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from halotools_ia.correlation_functions import  ed_3d, ee_3d,gi_plus_3d, gi_plus_projected, ii_minus_3d, ii_minus_projected, ii_plus_3d, ii_plus_projected, ed_projected, ed_3d_one_two_halo_decomp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee030ed-0c33-4497-958c-23ecb05d73d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tng = pickle.load(  open('/jet/home/yjagvara/SO3Diffusion_Tidal/TNG100-1_99_non-reduced_galaxy_shapes_multi_scale_1024_MLP_only_cent.pkl', \"rb\" ) )\n",
    "tng = tng[tng['dm_mass']>0]\n",
    "tng = tng[log10(tng['dm_mass']*10**10)>9]\n",
    "tng = tng[log10(tng['mass']*10**10)>9]\n",
    "\n",
    "tng['mass'] = log10(tng['mass']*10**10)\n",
    "tng['mass'] = (tng['mass']  -jnp.mean(tng['mass']))/ jnp.std(tng['mass']) \n",
    "tng['dm_mass'] = log10(tng['dm_mass']*10**10)\n",
    "tng['dm_mass'] = (tng['dm_mass']  -jnp.mean(tng['dm_mass']))/ jnp.std(tng['dm_mass']) \n",
    "\n",
    "#tng = tng[tng['central_bool']==1.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aaedd1",
   "metadata": {},
   "source": [
    "## Process the data for SO(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9538258",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flat_mat_I = np.array( (tng['dm_av_x'], tng['dm_av_y'], tng['dm_av_z'], \n",
    "tng['dm_bv_x'], tng['dm_bv_y'], tng['dm_bv_z'],\n",
    "tng['dm_cv_x'], tng['dm_cv_y'], tng['dm_cv_z'])).T\n",
    "\n",
    "rot_mat_I = np.reshape(flat_mat_I, (len(flat_mat_I), 3, 3), order='F' )\n",
    "\n",
    "for i in range (len(rot_mat_I)):\n",
    "    if np.linalg.det(rot_mat_I[i] ) < 0:\n",
    "        rot_mat_I[i] = rot_mat_I[i] @ (np.eye(3)*-1)\n",
    "        \n",
    "flat_mat_T = np.array( (   tng['tid_av_x_0.5_1024'], tng['tid_av_y_0.5_1024'], tng['tid_av_z_0.5_1024'], \n",
    "tng['tid_bv_x_0.5_1024'], tng['tid_bv_y_0.5_1024'], tng['tid_bv_z_0.5_1024'],\n",
    "tng['tid_cv_x_0.5_1024'], tng['tid_cv_y_0.5_1024'], tng['tid_cv_z_0.5_1024']   )).T\n",
    "\n",
    "\n",
    "flat_scalar_T =  np.array((tng['tid_a_0.5_1024'],  tng['tid_b_0.5_1024'],  tng['tid_c_0.5_1024'])).T\n",
    "rot_mat_T = np.reshape(flat_mat_T, (len(flat_mat_T), 3, 3), order='F' )\n",
    "\n",
    "for i in range (len(rot_mat_T)):\n",
    "    if np.linalg.det(rot_mat_T[i] ) < 0:\n",
    "        rot_mat_T[i] = rot_mat_T[i] @ (np.eye(3)*-1)\n",
    "        \n",
    "\n",
    "pos_tng = np.array([tng['gal_pos_x'], tng['gal_pos_y'], tng['gal_pos_z']]).T\n",
    "quat_I = jax.vmap(lambda x: SO3.from_matrix(x).wxyz) (rot_mat_I)\n",
    "quat_T = jax.vmap(lambda x: SO3.from_matrix(x).wxyz) (rot_mat_T)\n",
    "ax_ang_T = jax.vmap(lambda x: SO3(x).log() ) (quat_T)\n",
    "data_dict = {'quat_I': quat_I, 'quat_T': quat_T, 'scalar_T': flat_scalar_T, 'a': jnp.array(tng['dm_a']), 'b': jnp.array(tng['dm_b']), 'c': jnp.array(tng['dm_c']) }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4523f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dist_std = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e296451",
   "metadata": {},
   "source": [
    "## Let's build the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a62847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_key='GroupID'\n",
    "pos_key=['gal_pos_x', 'gal_pos_y', 'gal_pos_z']\n",
    "scalar_key = ['mass', 'dm_mass']\n",
    "catalog = tng\n",
    "\n",
    " \n",
    "# It takes a minute but we precompute all the graphs and data\n",
    "# Identify the individual groups and pre-extract the relevant data\n",
    "\n",
    "group_ids = catalog[group_key].astype(jnp.int32)\n",
    "gids, idx = jnp.unique(group_ids, return_index=True) # gids are the unique group ids, in other words All the host halo IDS uniquely  extracted     idx = The indices of the first occurrences of the unique values in the original array. i.e index of the central galaxy\n",
    "Position = jnp.array(catalog[pos_key].to_pandas())\n",
    "Scalars = jnp.array(catalog[scalar_key].to_pandas())\n",
    "quat_I = jnp.array(quat_I)\n",
    "quat_T = jnp.array(quat_T)\n",
    "flat_scalar_T = jnp.array(flat_scalar_T)\n",
    "\n",
    "Scalars = jnp.concatenate([Scalars, flat_scalar_T], axis=-1)\n",
    "quat_I_T = jnp.concatenate([quat_I, quat_T], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28bd984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17457, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quat_I_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dec195a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scalar = 5 #number of scalar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de74b5ed-3dae-4a49-bbc6-c8f91b3e5485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10292/10292 [00:41<00:00, 250.25it/s]\n"
     ]
    }
   ],
   "source": [
    "graph_radius = 1 #Mpc/h\n",
    "graphs_list = []\n",
    "node_features_list = []\n",
    "positions_list = []\n",
    "direction_to_COM_list = []\n",
    "quat_list = []\n",
    "\n",
    "\n",
    "for gid in tqdm(gids):\n",
    "    \n",
    "    g = np.where(group_ids == gid)[0]\n",
    "    Positions_for_group = Position[g]\n",
    "    Features_for_group = Scalars[g]\n",
    "    quat_I_T_for_group = quat_I_T[g]\n",
    "\n",
    "    #keep only halos with more than 10 galaxies\n",
    "    if Features_for_group.shape[0] >10:\n",
    "\n",
    "        # Compute adjacency matrix for each entry\n",
    "        graph = radius_neighbors_graph(Positions_for_group, graph_radius, mode='connectivity',\n",
    "                                   include_self=False)\n",
    "\n",
    "        Positions_for_group_COM =  (Positions_for_group - Positions_for_group[0])\n",
    "        directions_to_COM = Positions_for_group_COM/jnp.linalg.norm(Positions_for_group_COM, axis=-1)[..., jnp.newaxis]\n",
    "\n",
    "\n",
    "        directions_to_COM = directions_to_COM.at[jnp.isnan(directions_to_COM)].set(0.0)\n",
    "\n",
    "        graphs_list.append(graph)\n",
    "        node_features_list.append(Features_for_group)\n",
    "\n",
    "        direction_to_COM_list.append(directions_to_COM)\n",
    "        positions_list.append(Positions_for_group_COM)\n",
    "        \n",
    "        quat_list.append(quat_I_T_for_group)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd627d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39f81f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_node = graphs_list[0].tocoo().shape[0]\n",
    "max_n_edge = graphs_list[0].tocoo().nnz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "babd3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "senders_list = []\n",
    "receivers_list = []\n",
    "n_node_list = []\n",
    "n_edge_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62db2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12261171",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:05<00:00, 23.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for single_graph in tqdm(graphs_list):\n",
    "    single_graph =  single_graph.tocoo()\n",
    "    \n",
    " \n",
    "    senders = single_graph.row.astype(jnp.int64)\n",
    "    receivers = single_graph.col.astype(jnp.int64)\n",
    "    values = single_graph.data.astype(jnp.int64)\n",
    "    n_node = jnp.asarray([single_graph.shape[0]])\n",
    " \n",
    "    values = np.array([0]) if values.size == 0 else values\n",
    "    n_edge = np.array([np.sum(values)])\n",
    "    senders = np.repeat(senders, values)\n",
    "    receivers = np.repeat(receivers, values)\n",
    "    \n",
    "    if len(senders) < max_n_edge:\n",
    "        senders = jnp.concatenate( [senders, -1*jnp.ones( max_n_edge - len(senders)  )] )\n",
    "        receivers = jnp.concatenate( [receivers, -1*jnp.ones(max_n_edge - len(receivers)   )] )\n",
    "        \n",
    "    \n",
    "     \n",
    "    senders_list.append( jnp.asarray(senders).astype(jnp.int32)  )\n",
    "    receivers_list.append( jnp.asarray(receivers).astype(jnp.int32) )\n",
    "    \n",
    "    n_node_list.append( jnp.asarray(n_node).astype(jnp.int32) )\n",
    "    n_edge_list.append( jnp.asarray(n_edge).astype(jnp.int32) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96f9da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_list_padded = []\n",
    "positions_list_padded = []\n",
    "direction_to_COM_list_padded = []\n",
    "quat_list_padded = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f91f274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:01<00:00, 68.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#here padding the node features with np.inf\n",
    "for quat in tqdm(quat_list ):\n",
    "    if len(quat) < max_n_node:\n",
    "        \n",
    "        quat = jnp.concatenate( [quat, 0*jnp.ones( (max_n_node-len(quat), jnp.squeeze(quat ).shape[-1])  )] )\n",
    "        \n",
    "    quat_list_padded.append( jnp.asarray(quat).astype(jnp.float32)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f028a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1958f135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:01<00:00, 67.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#here padding the node features with np.inf\n",
    "for direction_to_COM in tqdm(direction_to_COM_list ):\n",
    "    if len(direction_to_COM) < max_n_node:\n",
    "        \n",
    "        direction_to_COM = jnp.concatenate( [direction_to_COM, 0*jnp.ones( (max_n_node-len(direction_to_COM), jnp.squeeze(direction_to_COM ).shape[-1])  )] )\n",
    "        \n",
    "    direction_to_COM_list_padded.append( jnp.asarray(direction_to_COM).astype(jnp.float32)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "280d4bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:01<00:00, 67.12it/s]\n"
     ]
    }
   ],
   "source": [
    "#here padding the node features with np.inf\n",
    "for node_features in tqdm(node_features_list ):\n",
    "    if len(node_features) < max_n_node:\n",
    "        \n",
    "        node_features = jnp.concatenate( [node_features, 0*jnp.ones( (max_n_node-len(node_features), jnp.squeeze(node_features ).shape[-1])  )] )\n",
    "        \n",
    "    node_features_list_padded.append( jnp.asarray(node_features).astype(jnp.float32)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ea28dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:00<00:00, 1444.88it/s]\n"
     ]
    }
   ],
   "source": [
    "#here padding the node features with np.inf\n",
    "for positions in tqdm(positions_list ):\n",
    "    if len(positions) < max_n_node:\n",
    "        \n",
    "        positions = jnp.concatenate( [positions, 0*jnp.ones( (max_n_node-len(positions), jnp.squeeze(positions ).shape[-1])  )] )\n",
    "        \n",
    "    positions_list_padded.append( jnp.asarray(positions).astype(jnp.float32)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecbda61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c75c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b238a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "senders_list = jnp.array(senders_list)\n",
    "receivers_list = jnp.array(receivers_list)\n",
    "\n",
    "n_node_list = jnp.array(n_node_list)\n",
    "n_edge_list = jnp.array(n_edge_list)\n",
    "\n",
    "node_features_list_padded = jnp.array(node_features_list_padded)\n",
    "positions_list_padded = jnp.array(positions_list_padded)\n",
    "direction_to_COM_list_padded = jnp.array(direction_to_COM_list_padded)\n",
    "quat_list_padded = jnp.array(quat_list_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9dac1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_feats = jnp.concatenate([node_features_list_padded, quat_list_padded,  direction_to_COM_list_padded, positions_list_padded], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bad61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GP =  gn_graph.GraphsTuple(\n",
    "      nodes=concat_feats,  \n",
    "      edges=-1*jnp.ones_like(n_node_list),\n",
    "      receivers= receivers_list   ,\n",
    "      senders= senders_list ,\n",
    "      globals=  -1*jnp.ones_like(n_node_list),\n",
    "      n_node=n_node_list,\n",
    "      n_edge=n_edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfc49d1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dset = tf.data.Dataset.from_tensor_slices(GP)\n",
    "\n",
    "dset = dset.repeat()\n",
    "dset = dset.shuffle(buffer_size=10000)\n",
    "dset = dset.batch(batch_size)\n",
    "dset = dset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "dset = dset.as_numpy_iterator()\n",
    "_ = next(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4613b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = next(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de2d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5a01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdbf1c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dset2 = tf.data.Dataset.from_tensor_slices(GP)\n",
    "\n",
    "dset2 = dset2.repeat()\n",
    "dset2 = dset2.shuffle(buffer_size=10000)\n",
    "dset2 = dset2.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "dset2 = dset2.as_numpy_iterator()\n",
    "g_init = next(dset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c058acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_e(feats: jnp.ndarray, in_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP([in_dim , in_dim ], activation=jax.nn.silu)(feats)\n",
    "  return net\n",
    "\n",
    "def f_inf(m_ij: jnp.ndarray, in_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP( [1,], activation=jax.nn.sigmoid)(m_ij)\n",
    "  return net\n",
    "\n",
    "def f_h(feats: jnp.ndarray, in_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP([in_dim,  ], activation=jax.nn.silu)(feats)\n",
    "  net = hk.Linear(in_dim)(net)\n",
    "  return net\n",
    "\n",
    "\n",
    "def f_x(feats: jnp.ndarray, in_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP([in_dim, in_dim  ], activation=jax.nn.silu)(feats)\n",
    "  net = hk.Linear(1)(net) \n",
    "  return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a86f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT modified\n",
    "def GNN(add_self_edges: bool = False ) -> Callable:\n",
    "  def _ApplyGNN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    " \n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    \n",
    "    \n",
    "    # Equivalent to the sum of n_node, but statically known.\n",
    "    try:\n",
    "      sum_n_node = nodes.shape[0]\n",
    "    except IndexError:\n",
    "      raise IndexError('GAT requires node features')\n",
    "\n",
    "    \n",
    "    \n",
    "    # position of the nodes are the last 3 entries in the features matrix\n",
    "    distances = jnp.linalg.norm( nodes[:,-3:][senders] - nodes[:,-3:][receivers], axis=-1)\n",
    "    node_feat = nodes[:,:n_scalar]\n",
    "    \n",
    "    input_dim = nodes[:,:n_scalar].shape[-1]\n",
    "    \n",
    "    \n",
    "    concat_feats = jnp.concatenate([ node_feat[senders], node_feat[receivers], distances.reshape((-1,1))**2 ], axis=-1)\n",
    "    m_ij = f_e(concat_feats, input_dim)\n",
    "    \n",
    "    \n",
    "    # predict edges\n",
    "    e_ij = f_inf(m_ij, input_dim)\n",
    "    \n",
    "    m_i = jraph_utils.segment_sum( e_ij*m_ij, receivers, num_segments=sum_n_node)\n",
    "\n",
    "    concat_for_hl1_i =  jnp.concatenate([node_feat,  m_i], axis=-1)\n",
    "    \n",
    "    \n",
    "    new_node_feat = node_feat + f_h(concat_for_hl1_i, input_dim) #h^(l+1)_i    f_h is the node update func\n",
    "\n",
    "     \n",
    "    position_mlp = f_x(concat_feats, input_dim)\n",
    "    prefac_xi_xj = (nodes[:,-3:][senders] - nodes[:,-3:][receivers])/ (distances.reshape((-1,1))+1)\n",
    "    \n",
    "    sum_xi_xj =  jraph_utils.segment_sum( prefac_xi_xj*position_mlp, receivers, num_segments=sum_n_node)\n",
    "    #sum_xi_xj = jnp.einsum('ij,ij ->i', prefac_xi_xj, position_mlp ) #f_x\n",
    "    \n",
    "    x_Lplus1_i = nodes[:,-3:] + sum_xi_xj\n",
    "      \n",
    "    \n",
    "    \n",
    "\n",
    "    x_Lplus1_i = x_Lplus1_i/jnp.linalg.norm(x_Lplus1_i, axis=-1 )[..., jnp.newaxis]\n",
    "    mask = jnp.isnan(x_Lplus1_i)  # boolean mask selecting non-nan values\n",
    "    x_Lplus1_i = jnp.where(~mask, x_Lplus1_i, 0)\n",
    "    \n",
    "    #x_Lplus1_i = jnp.nan_to_num(x_Lplus1_i, copy=False,nan=0.0, posinf=0.0, neginf=0.0)#    x_Lplus1_i.at[jnp.isnan(x_Lplus1_i)].set(0.0)\n",
    "    \n",
    "    \n",
    "    nodes = jnp.concatenate([new_node_feat, nodes[:,n_scalar:-3], x_Lplus1_i],axis=-1)\n",
    "    #print(nodes.shape)\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  # pylint: enable=g-long-lambda\n",
    "  return _ApplyGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0fb32af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_expand_MLP(feats: jnp.ndarray, out_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.nets.MLP( [out_dim] )(feats)\n",
    "  return net\n",
    "\n",
    "\n",
    "def dim_expand(graph: jraph.GraphsTuple, out_dim) -> jraph.GraphsTuple:\n",
    "\n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    node_feat = nodes[:,:n_scalar]\n",
    "    new_node = dim_expand_MLP(node_feat, out_dim)\n",
    "    nodes = jnp.concatenate([new_node, nodes[:,n_scalar:]],axis=-1)\n",
    "    return graph._replace(nodes=nodes)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebdb52",
   "metadata": {},
   "source": [
    "## The Noiser: takes in a batch ads noise and estimates the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b540648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b965504",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def noiser_pre(graph, key, noise_dist_std=noise_dist_std):\n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    nodes_scalar = nodes[...,  :n_scalar]\n",
    "    nodes_so3 = nodes[...,n_scalar:-6]\n",
    "    nodes_I = nodes_so3[...,:4]\n",
    "    nodes_T = nodes_so3[...,4:]\n",
    "    #print(key.shape)    \n",
    "    if key.shape[0] == 2:\n",
    "        key1, key2 =jax.random.split(key)\n",
    "    else: key1, key2 =jax.random.split(key[0])\n",
    "    # Sample random noise from target noise distribution\n",
    "    s = noise_dist_std * jnp.abs(jax.random.normal(shape=[nodes_I.shape[0]], key=key1)) + 1e-3\n",
    "    \n",
    "    @jax.vmap\n",
    "    def sample(quatX, scale ,   key ):\n",
    "        #key =jax.random.split(key, quatX.shape[0])\n",
    "        \n",
    "\n",
    "        dist_quat = IsotropicGaussianSO3(quatX, scale)\n",
    "\n",
    "        quatY = dist_quat.sample(seed=key)\n",
    " \n",
    "        \n",
    "        def fn_quat(s_direction, val):\n",
    "            return dist_quat.log_prob( (SO3(val) @ SO3.exp(s_direction)).wxyz) \n",
    "        score_so3 = jax.grad(fn_quat)(jnp.zeros(3), quatY )   #direction of the derivative, can be chosen to be the identity\n",
    "        \n",
    "        return jnp.concatenate([quatY, score_so3, scale.reshape([1])], axis=-1) \n",
    "        #return { 'x_so3': quatX, 'y_so3': quatY, \n",
    "                 #'score_so3': score_so3, 's':scale.reshape([1]) }\n",
    "\n",
    "    noised_sample = sample( nodes_I,   s , jax.random.split(key2, nodes_I.shape[0]))\n",
    "\n",
    "    nodes= jnp.concatenate([nodes_scalar, nodes_so3, noised_sample, nodes[..., -6:] ], axis=-1)\n",
    "    return graph._replace(nodes=nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc5f07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MLP_so3(so3, feats, stdev, tensor_T):\n",
    "    \n",
    "    so3_log = jax.vmap(lambda u: SO3(u).log())(so3)\n",
    "    net = jnp.concatenate([so3_log, feats, stdev, tensor_T],axis=-1)\n",
    "    net = hk.nets.MLP([256,256,256], activation=jax.nn.leaky_relu)(net)\n",
    "    net = hk.Linear( 3)(net)  \n",
    "    return net/stdev \n",
    "\n",
    "\n",
    "def so3_SGM_layer(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "\n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    \n",
    "    nodes_scalar = nodes[:, :n_scalar]\n",
    "    nodes_so3 = nodes[:,n_scalar:n_scalar+8]\n",
    "    nodes_I = nodes_so3[:,:4]\n",
    "    nodes_T = nodes_so3[:,4:]\n",
    "    \n",
    "    noised_I = nodes[:,n_scalar+8:n_scalar+8+4]\n",
    " \n",
    "    noised_I_score = nodes[:, n_scalar+8+4:n_scalar+8+4+3]\n",
    "    stdev = nodes[:, n_scalar+8+4+3:n_scalar+8+4+3+1]\n",
    "    #noised_I, noised_I_score, stdev = noiser(nodes_I, key, noise_dist_std=noise_dist_std)\n",
    "    \n",
    "    output_score = MLP_so3(noised_I, nodes_scalar, stdev, nodes_T)\n",
    "    return output_score, noised_I_score\n",
    "#     nodes = jnp.concatenate([new_node, nodes[:,n_scalar:]],axis=-1)\n",
    "    \n",
    "#     return graph._replace(nodes=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c0598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afca7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "def gcn_definition(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "  \"\"\"Defines a GCN for the karate club task.\n",
    "  Args:\n",
    "    graph: GraphsTuple the network processes.\n",
    "\n",
    "  Returns:\n",
    "    output graph with updated node values.\n",
    "  \"\"\"\n",
    "  #graph = dim_expand(graph,   32)\n",
    "    \n",
    "  gn = GNN( \n",
    "      add_self_edges=False )\n",
    "  graph = gn(graph)\n",
    "  \n",
    "  \n",
    "\n",
    "  gn = GNN(add_self_edges=False) # output dim is 2 because we have 2 scalars.\n",
    "  graph = gn(graph)\n",
    "    \n",
    "  #graph = dim_expand(graph,   32)\n",
    "  #key = next(rng)\n",
    "  output_score, true_score = so3_SGM_layer(graph )#only do node operations, no messages\n",
    "\n",
    "\n",
    "  return output_score, true_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b6aa9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import config \n",
    "config.update(\"jax_debug_nans\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85f80bce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network = hk.without_apply_rng(hk.transform(gcn_definition ))\n",
    "\n",
    "\n",
    "#params = jax.vmap(lambda x: network.init( next(rng) , x))  (g)\n",
    "g_init = noiser_pre(g_init,  next(rng) , noise_dist_std=noise_dist_std)\n",
    "\n",
    "params =  network.init( next(rng) , g_init )\n",
    "\n",
    "#out_graph = jax.vmap(lambda x,y: network.apply(x,y))   (params, g)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d89a2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def prediction_loss(params: hk.Params, graph_batch: jraph.GraphsTuple, key ) -> jnp.ndarray:\n",
    "    \n",
    "    predicted_graph = jax.vmap ( lambda x: network.apply(params, x )) (graph_batch)\n",
    "    score_pred = predicted_graph[0]\n",
    "    score_true = predicted_graph[1]\n",
    "    \n",
    "    loss =  jnp.linalg.norm(score_pred   -  score_true, axis=-1) **2\n",
    "    \n",
    "    return jnp.mean(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6d48a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update = optax.adam(1e-3)\n",
    "opt_state = opt_init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ccff342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  jax.random.split(jax.random.PRNGKey(0), 64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94e33512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.random.PRNGKey(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69e1dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(params: hk.Params, opt_state, graph_batch: jraph.GraphsTuple, key) -> Tuple[hk.Params, Any]:\n",
    "    \n",
    "    key1, key2 =jax.random.split(key)\n",
    "\n",
    "    #graph_batch =  noiser_pre( graph_batch, jax.random.PRNGKey(0) ) \n",
    "\n",
    "    graph_batch = jax.vmap ( lambda x: noiser_pre( x,   jax.random.split(jax.random.PRNGKey(0), 64))) (graph_batch  )\n",
    "\n",
    "    loss, grads = jax.value_and_grad(prediction_loss)(params, graph_batch, key2)\n",
    "\n",
    "    updates, opt_state = opt_update(grads, opt_state)\n",
    "    \n",
    "    return optax.apply_updates(params, updates), opt_state, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e3b231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "params_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110b065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4011be02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for step in tqdm(range(10_000)):\n",
    "    params, opt_state, loss = update(params, opt_state, next(dset), next(rng)  )\n",
    "\n",
    "    print(loss)\n",
    "    if jnp.isnan(loss):\n",
    "        break\n",
    "    \n",
    "    if step%10==0 or step==0:\n",
    "        pickle.dump( params_list, open( \"/ocean/projects/phy210062p/yjagvara/EGNN_so3_weights.p\", \"wb\" ) )\n",
    "        pickle.dump( losses, open( \"/ocean/projects/phy210062p/yjagvara/EGNN_so3_losses.p\", \"wb\" ) )\n",
    "        losses.append(loss)\n",
    "        params_list.append(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c5ad5",
   "metadata": {},
   "source": [
    "losses = pickle.load(open( \"/ocean/projects/phy210062p/yjagvara/EGNN_losses.p\", \"rb\" ))\n",
    "params_list = pickle.load(open( \"/ocean/projects/phy210062p/yjagvara/EGNN_weights.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b507138f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1486b5155280>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10c96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0252a3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predicted_graph \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mGP\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predicted_graph \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap ( \u001b[38;5;28;01mlambda\u001b[39;00m x: network\u001b[38;5;241m.\u001b[39mapply(\u001b[43mparams_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, x)) (GP)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "predicted_graph = jax.vmap ( lambda x: network.apply(params_list[-1], x)) (GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "GP.nodes[:,:,n_scalar:n_scalar+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39801e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = jnp.einsum('...k,...k->...' ,  predicted_graph.nodes, GP.nodes[:,:,n_scalar:n_scalar+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b700c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_new = np.ma.masked_equal(t,0)\n",
    "print(t_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd4fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=hist(t_new[:20],bins=10,density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2143e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=hist(t_new[5],bins=20,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c248f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe60d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd9711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfd166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca68d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45d602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27412dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d999a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2aee7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c213cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def noiser(nodes_I, key, noise_dist_std=noise_dist_std):\n",
    "    key1, key2 =jax.random.split(key)\n",
    "    # Sample random noise from target noise distribution\n",
    "    s = noise_dist_std * jnp.abs(jax.random.normal(shape=[nodes_I.shape[0]], key=key1)) + 1e-3\n",
    "    @jax.vmap\n",
    "    def sample(quatX, scale,   seed ):\n",
    "        key3, key4 =jax.random.split(seed)\n",
    "        \n",
    "        dist_quat = IsotropicGaussianSO3(quatX, scale)\n",
    "        quatY = dist_quat.sample(seed=key3)\n",
    " \n",
    "        \n",
    "        def fn_quat(s_direction, val):\n",
    "            return dist_quat.log_prob( (SO3(val) @ SO3.exp(s_direction)).wxyz) \n",
    "        score_so3 = jax.grad(fn_quat)(jnp.zeros(3), quatY )   #direction of the derivative, can be chosen to be the identity\n",
    "        \n",
    "        return quatY, score_so3, scale.reshape([1])\n",
    "        #return { 'x_so3': quatX, 'y_so3': quatY, \n",
    "                 #'score_so3': score_so3, 's':scale.reshape([1]) }\n",
    "    \n",
    "    \n",
    "    # Generates training set batch\n",
    "  \n",
    "    return sample( nodes_I, s, jax.random.split(key2, nodes_I.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592482e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@jraph.concatenated_args\n",
    "def node_update_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.Sequential(\n",
    "      [hk.Linear(128), jax.nn.relu,\n",
    "       hk.Linear(128)])\n",
    "  return net(feats)\n",
    "\n",
    "\n",
    "def net_fn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "  # Add a global paramater for graph classification.\n",
    "  graph = graph._replace(globals=jnp.zeros([graph.n_node.shape[0], 1]))\n",
    "  embedder = jraph.GraphMapFeatures(\n",
    "      hk.Linear(128), hk.Linear(128), hk.Linear(128))\n",
    "  net = jraph.GraphNetwork(\n",
    "      update_node_fn=node_update_fn,\n",
    "      update_edge_fn=edge_update_fn,\n",
    "      update_global_fn=update_global_fn)\n",
    "  return net(embedder(graph)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d4f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(params: hk.Params, graph: jraph.GraphsTuple, label: jnp.ndarray,\n",
    "                 net: jraph.GraphsTuple) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "  \"\"\"Computes loss and accuracy.\"\"\"\n",
    "  pred_graph = net.apply(params, graph)\n",
    "  preds = jax.nn.log_softmax(pred_graph.globals)\n",
    "  targets = jax.nn.one_hot(label, 2)\n",
    "\n",
    "  # Since we have an extra 'dummy' graph in our batch due to padding, we want\n",
    "  # to mask out any loss associated with the dummy graph.\n",
    "  # Since we padded with `pad_with_graphs` we can recover the mask by using\n",
    "  # get_graph_padding_mask.\n",
    "  mask = jraph.get_graph_padding_mask(pred_graph)\n",
    "\n",
    "  # Cross entropy loss.\n",
    "  loss = -jnp.mean(preds * targets * mask[:, None])\n",
    "\n",
    "  # Accuracy taking into account the mask.\n",
    "  accuracy = jnp.sum(\n",
    "      (jnp.argmax(pred_graph.globals, axis=1) == label) * mask) / jnp.sum(mask)\n",
    "  return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/ogb_examples/train.py\n",
    "def train(dataset: List[Dict[str, Any]], num_train_steps: int) -> hk.Params:\n",
    "  \"\"\"Training loop.\"\"\"\n",
    "\n",
    "  # Transform impure `net_fn` to pure functions with hk.transform.\n",
    "  net = hk.without_apply_rng(hk.transform(net_fn))\n",
    "  # Get a candidate graph and label to initialize the network.\n",
    "  graph = dataset[0]['input_graph']\n",
    "\n",
    "  # Initialize the network.\n",
    "  params = net.init(jax.random.PRNGKey(42), graph)\n",
    "  # Initialize the optimizer.\n",
    "  opt_init, opt_update = optax.adam(1e-4)\n",
    "  opt_state = opt_init(params)\n",
    "\n",
    "  compute_loss_fn = functools.partial(compute_loss, net=net)\n",
    "  # We jit the computation of our loss, since this is the main computation.\n",
    "  # Using jax.jit means that we will use a single accelerator. If you want\n",
    "  # to use more than 1 accelerator, use jax.pmap. More information can be\n",
    "  # found in the jax documentation.\n",
    "  compute_loss_fn = jax.jit(jax.value_and_grad(\n",
    "      compute_loss_fn, has_aux=True))\n",
    "\n",
    "  for idx in range(num_train_steps):\n",
    "    graph = dataset[idx % len(dataset)]['input_graph']\n",
    "    label = dataset[idx % len(dataset)]['target']\n",
    "    # Jax will re-jit your graphnet every time a new graph shape is encountered.\n",
    "    # In the limit, this means a new compilation every training step, which\n",
    "    # will result in *extremely* slow training. To prevent this, pad each\n",
    "    # batch of graphs to the nearest power of two. Since jax maintains a cache\n",
    "    # of compiled programs, the compilation cost is amortized.\n",
    "    graph = pad_graph_to_nearest_power_of_two(graph)\n",
    "\n",
    "    # Since padding is implemented with pad_with_graphs, an extra graph has\n",
    "    # been added to the batch, which means there should be an extra label.\n",
    "    label = jnp.concatenate([label, jnp.array([0])])\n",
    "\n",
    "    (loss, acc), grad = compute_loss_fn(params, graph, label)\n",
    "    updates, opt_state = opt_update(grad, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    if idx % 50 == 0:\n",
    "      print(f'step: {idx}, loss: {loss}, acc: {acc}')\n",
    "  print('Training finished')\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = train(train_mutag_ds, num_train_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dfa6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28355cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(hk.Module):\n",
    "  def __init__(self, features: jnp.ndarray):\n",
    "    super().__init__()\n",
    "    self.features = features\n",
    "\n",
    "  def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "    layers = []\n",
    "    for feat in self.features[:-1]:\n",
    "      layers.append(hk.Linear(feat))\n",
    "      layers.append(jax.nn.relu)\n",
    "    layers.append(hk.Linear(self.features[-1]))\n",
    "\n",
    "    mlp = hk.Sequential(layers)\n",
    "    return mlp(x)\n",
    "\n",
    "# Use MLP block to define the update node function\n",
    "update_node_fn = lambda x: MLP(features=[8, 4])(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18233c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L506\n",
    "def GraphConvolution(update_node_fn: Callable,\n",
    "                     aggregate_nodes_fn: Callable = jax.ops.segment_sum,\n",
    "                     add_self_edges: bool = False,\n",
    "                     symmetric_normalization: bool = False) -> Callable:\n",
    "  \"\"\"Returns a method that applies a Graph Convolution layer.\n",
    "\n",
    "  Graph Convolutional layer as in https://arxiv.org/abs/1609.02907,\n",
    "  NOTE: This implementation does not add an activation after aggregation.\n",
    "  If you are stacking layers, you may want to add an activation between\n",
    "  each layer.\n",
    "  Args:\n",
    "    update_node_fn: function used to update the nodes. In the paper a single\n",
    "      layer MLP is used.\n",
    "    aggregate_nodes_fn: function used to aggregates the sender nodes.\n",
    "    add_self_edges: whether to add self edges to nodes in the graph as in the\n",
    "      paper definition of GCN. Defaults to False.\n",
    "    symmetric_normalization: whether to use symmetric normalization. Defaults to\n",
    "      True.\n",
    "\n",
    "  Returns:\n",
    "    A method that applies a Graph Convolution layer.\n",
    "  \"\"\"\n",
    "\n",
    "  def _ApplyGCN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "    \"\"\"Applies a Graph Convolution layer.\"\"\"\n",
    "    nodes, _, receivers, senders, _, _, _ = graph\n",
    "\n",
    "    # First pass nodes through the node updater.\n",
    "    nodes = update_node_fn(nodes)\n",
    "    # Equivalent to jnp.sum(n_node), but jittable\n",
    "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
    "    if add_self_edges:\n",
    "      # We add self edges to the senders and receivers so that each node\n",
    "      # includes itself in aggregation.\n",
    "      # In principle, a `GraphsTuple` should partition by n_edge, but in\n",
    "      # this case it is not required since a GCN is agnostic to whether\n",
    "      # the `GraphsTuple` is a batch of graphs or a single large graph.\n",
    "      conv_receivers, conv_senders = add_self_edges_fn(receivers, senders,\n",
    "                                                       total_num_nodes)\n",
    "    else:\n",
    "      conv_senders = senders\n",
    "      conv_receivers = receivers\n",
    "\n",
    "    # pylint: disable=g-long-lambda\n",
    "    if symmetric_normalization:\n",
    "      # Calculate the normalization values.\n",
    "      count_edges = lambda x: jax.ops.segment_sum(\n",
    "          jnp.ones_like(conv_senders), x, total_num_nodes)\n",
    "      sender_degree = count_edges(conv_senders)\n",
    "      receiver_degree = count_edges(conv_receivers)\n",
    "\n",
    "      # Pre normalize by sqrt sender degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: x * jax.lax.rsqrt(jnp.maximum(sender_degree, 1.0))[:, None],\n",
    "          nodes,\n",
    "      )\n",
    "      # Aggregate the pre-normalized nodes.\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "      # Post normalize by sqrt receiver degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x:\n",
    "          (x * jax.lax.rsqrt(jnp.maximum(receiver_degree, 1.0))[:, None]),\n",
    "          nodes,\n",
    "      )\n",
    "    else:\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "    # pylint: enable=g-long-lambda\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  return _ApplyGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "  \"\"\"Defines a graph neural network with 3 GCN layers.\n",
    "  Args:\n",
    "    graph: GraphsTuple the network processes.\n",
    "\n",
    "  Returns:\n",
    "    output graph with updated node values.\n",
    "  \"\"\"\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=lambda n: jax.nn.relu(hk.Linear(8)(n)),\n",
    "      add_self_edges=False)\n",
    "  graph = gn(graph)\n",
    "\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=lambda n: jax.nn.relu(hk.Linear(4)(n)),\n",
    "      add_self_edges=False)\n",
    "  graph = gn(graph)\n",
    "\n",
    "  gn = GraphConvolution(\n",
    "      update_node_fn=hk.Linear(2))\n",
    "  graph = gn(graph)\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525be495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21324b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L506\n",
    "def GraphConvolution(update_node_fn: Callable,\n",
    "                     aggregate_nodes_fn: Callable = jax.ops.segment_sum,\n",
    "                     add_self_edges: bool = False,\n",
    "                     symmetric_normalization: bool = False) -> Callable:\n",
    "  \"\"\"Returns a method that applies a Graph Convolution layer.\n",
    "\n",
    "  Graph Convolutional layer as in https://arxiv.org/abs/1609.02907,\n",
    "  NOTE: This implementation does not add an activation after aggregation.\n",
    "  If you are stacking layers, you may want to add an activation between\n",
    "  each layer.\n",
    "  Args:\n",
    "    update_node_fn: function used to update the nodes. In the paper a single\n",
    "      layer MLP is used.\n",
    "    aggregate_nodes_fn: function used to aggregates the sender nodes.\n",
    "    add_self_edges: whether to add self edges to nodes in the graph as in the\n",
    "      paper definition of GCN. Defaults to False.\n",
    "    symmetric_normalization: whether to use symmetric normalization. Defaults to\n",
    "      True.\n",
    "\n",
    "  Returns:\n",
    "    A method that applies a Graph Convolution layer.\n",
    "  \"\"\"\n",
    "\n",
    "  def _ApplyGCN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "    \"\"\"Applies a Graph Convolution layer.\"\"\"\n",
    "    nodes, _, receivers, senders, _, _, _ = graph\n",
    "\n",
    "    # First pass nodes through the node updater.\n",
    "    nodes = update_node_fn(nodes)\n",
    "    # Equivalent to jnp.sum(n_node), but jittable\n",
    "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
    "    if add_self_edges:\n",
    "      # We add self edges to the senders and receivers so that each node\n",
    "      # includes itself in aggregation.\n",
    "      # In principle, a `GraphsTuple` should partition by n_edge, but in\n",
    "      # this case it is not required since a GCN is agnostic to whether\n",
    "      # the `GraphsTuple` is a batch of graphs or a single large graph.\n",
    "      conv_receivers, conv_senders = add_self_edges_fn(receivers, senders,\n",
    "                                                       total_num_nodes)\n",
    "    else:\n",
    "      conv_senders = senders\n",
    "      conv_receivers = receivers\n",
    "\n",
    "    # pylint: disable=g-long-lambda\n",
    "    if symmetric_normalization:\n",
    "      # Calculate the normalization values.\n",
    "      count_edges = lambda x: jax.ops.segment_sum(\n",
    "          jnp.ones_like(conv_senders), x, total_num_nodes)\n",
    "      sender_degree = count_edges(conv_senders)\n",
    "      receiver_degree = count_edges(conv_receivers)\n",
    "\n",
    "      # Pre normalize by sqrt sender degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: x * jax.lax.rsqrt(jnp.maximum(sender_degree, 1.0))[:, None],\n",
    "          nodes,\n",
    "      )\n",
    "      # Aggregate the pre-normalized nodes.\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "      # Post normalize by sqrt receiver degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x:\n",
    "          (x * jax.lax.rsqrt(jnp.maximum(receiver_degree, 1.0))[:, None]),\n",
    "          nodes,\n",
    "      )\n",
    "    else:\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "    # pylint: enable=g-long-lambda\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  return _ApplyGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044347fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT modified\n",
    "def GNN(add_self_edges: bool = False ) -> Callable:\n",
    " \n",
    " \n",
    "\n",
    "  def _ApplyGNN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    " \n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    \n",
    "    \n",
    "    #Equivalent to the sum of n_node, but statically known.\n",
    "    try:\n",
    "      sum_n_node = nodes.shape[0]\n",
    "    except IndexError:\n",
    "      raise IndexError('GAT requires node features')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # position of the nodes are the last 3 entries in the features matrix\n",
    "    \n",
    "    distances = jnp.linalg.norm( nodes[:,:3][senders] - nodes[:,:3][receivers], axis=-1)\n",
    "    node_feat = nodes[:,3:]\n",
    "    \n",
    "    input_dim = nodes[:,3:].shape[-1]\n",
    "    \n",
    "    \n",
    "    concat_feats = jnp.concatenate([ node_feat[senders], node_feat[receivers], distances.reshape((-1,1))**2 ], axis=-1)\n",
    "    m_ij = f_e(concat_feats, input_dim)\n",
    "    \n",
    "    \n",
    "    # predict edges\n",
    "    e_ij = f_inf(m_ij, input_dim)\n",
    "    \n",
    "    m_i = jraph_utils.segment_sum( e_ij*m_ij, receivers, num_segments=sum_n_node)\n",
    "\n",
    "    concat_for_hl1_i =  jnp.concatenate([node_feat,  m_i], axis=-1)\n",
    "    \n",
    "    \n",
    "    new_node_feat = node_feat + f_h(concat_for_hl1_i, input_dim) #h^(l+1)_i    f_h is the node update func\n",
    "\n",
    "     \n",
    "    position_mlp = f_x(concat_feats, input_dim)\n",
    "    prefac_xi_xj = (nodes[:,:3][senders] - nodes[:,:3][receivers])/ (distances.reshape((-1,1))+1)\n",
    "    \n",
    "    sum_xi_xj =  jraph_utils.segment_sum( prefac_xi_xj*position_mlp, receivers, num_segments=sum_n_node)\n",
    "    #sum_xi_xj = jnp.einsum('ij,ij ->i', prefac_xi_xj, position_mlp ) #f_x\n",
    "    \n",
    "    x_Lplus1_i = nodes[:,:3] + sum_xi_xj\n",
    "    \n",
    "    nodes = jnp.concatenate([x_Lplus1_i, new_node_feat],axis=-1)\n",
    "    #print(nodes.shape)\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  # pylint: enable=g-long-lambda\n",
    "  return _ApplyGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ed5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_expand_MLP(feats: jnp.ndarray, out_dim) -> jnp.ndarray:\n",
    "  \"\"\"Node update function for graph net.\"\"\"\n",
    "  net = hk.Linear( out_dim )(feats)\n",
    "  return net\n",
    "\n",
    "\n",
    "def dim_expand(graph: jraph.GraphsTuple, out_dim) -> jraph.GraphsTuple:\n",
    "\n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "\n",
    "    node_feat = nodes[:,3:]\n",
    "    in_dim = nodes[:,3:].shape[-1]\n",
    "    new_node = dim_expand_MLP(node_feat, out_dim)\n",
    "    \n",
    "    nodes = jnp.concatenate([nodes[:,:3], new_node],axis=-1)\n",
    "\n",
    "     \n",
    "    return graph._replace(nodes=nodes)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe45fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
